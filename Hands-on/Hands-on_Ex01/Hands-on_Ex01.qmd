---
title: "Geospatial Data Wrangling with R"
---

For this hands-on exercise, we perform basic data wrangling tasks using the sf package in R. The content is based on

# Getting Started

## Data Sources

The exercise will use the following publicly available datasets:

-   Master Plan 2014 Subzone Boundary from [data.gov.sg](https://beta.data.gov.sg/datasets/d_d14da225fccf921049ab64238ff473d9/view)

-   Pre-Schools location from [data.gov.sg](https://beta.data.gov.sg/datasets/d_61eefab99958fd70e6aab17320a71f1c/view)

-   Cycling Path from [LTA DataMall](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/CyclingPath_Jul2024.zip)

-   Singapore AirBNB listing data from [Inside AirBNB](https://insideairbnb.com/get-the-data/)

The files from the first three are loaded into a folder named `geospatial`, while the last one (AirBNB listings) is loaded into a folder named `aspatial`.

## Installing and launching R packages

This exercise will make use of two R packages: **sf** and **tidyverse**. **Tidyverse** is a family of R packages used for data wrangling and visualization. **Sf** is used for importing, managing and processing geospatial data.

The code chunk below uses `p_load()` of **pacman** package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.

```{r}
pacman::p_load(sf, tidyverse)
```

# Importing Geospatial Data

The `st_read()` function of the **sf** package is used to load geospatial data into R

## Importing polygon feature data in shapefile format

`MP14_SUBZONE_WEB_PL` is a polygon feature layer in ESRI shapefile format from the first data source. (Master Plan 2014 Subzone Boundary from data.gov.sg) This will get loaded into R as a polygon feature data frame.

The `st_read()` function call for ESRI shapefiles requires two arguments: `dsn` which defines the path, and `layer` which defines the shapefile name. The path only requires a folder and therefore does not require a file (with an extension) to be named. We load this data into a dataframe `mpsz`.

```{r}
mpsz = st_read(dsn = "data/geospatial", 
                  layer = "MP14_SUBZONE_WEB_PL")
```

The message confirms that the load is successful and that the objects are multipolygon features. It also gives information on the number of features (323), fields (15) and the coordinate system. (SVY21) The bounding box value defines the extent of the data.

## Importing polyline feature data in shapefile format

`CyclingPath` is a line feature layer in ESRI shapefile format from the third data source. (Cycling Path from LTA) This will get loaded into R as a line feature data frame.

A similar function call is used to load the data into R as a dataframe `cyclingpath`.

```{r}
cyclingpath = st_read(dsn = "data/geospatial", 
                         layer = "CyclingPathGazette")
```

The message confirms the type (Multistring), the number of features (3138) and fields (2) among other information.

## Importing GIS data in kml format

`PreSchoolsLocation` is a point feature layer in kml format from the second data source. (Preschools Location from data.gov.sg)

The `st_read()` function call for KML files requires one parameter, which is the complete path, including the kml filename. We load this data into a dataframe `preschool`.

```{r}
preschool = st_read("data/geospatial/PreSchoolsLocation.kml")
```

The message confirms the type (Point), the number of features (2290) and fields (2) among other information.

# Checking the Content of a Simple Feature Data Frame

There are different ways to retrieve information from a simple feature data frame.

## Working with `st_geometry()`

The `geometry` column in the sf dataframe is a list of class `sfc` which contains the geometries. The contents of the column can be retrieved by:

-   calling the column using `mpsz$geometry` , `mpsz$geom` , or `mpsz[[1]]`

-   using the function `st_geometry()`

```{r}
st_geometry(mpsz)
```

## Working with `glimpse()`

The `glimpse()` function from **dplyr** reveals the data type of each field and gives the first few observations.

```{r}
glimpse(mpsz)
```

## Working with `head()`

The Base R `head()` function reveals the first elements of the dataframe. The number of elements can be set by specifying an `n` argument. It also displays information for an sf dataframe like the geometry type, bounding box and projection system.

```{r}
head(mpsz, n = 5)
```

# Plotting Geospatial Data with `plot()`

The `plot()` function of R Graphic allows us to display the content of an sf dataframe as a map visualization.

```{r}
plot(mpsz)
```

The default output of from running an sf object in `plot()` is a multi-plot of all attributes, or a reasonable number of attributes. For the case of `mpsz`, the function gives a multiplot of the first 9 attributes. We can generate a plot for just `geometry` by using the following code:

```{r}
plot(st_geometry(mpsz))
```

Individual columns or attributes of an sf object can be plotted using the following approach. In this case, we are interested in the column / feature `PLN_AREA_N`

```{r}
mpsz["PLN_AREA_N"]
```

Note that `plot()` is primarily used to generate quick visualizations. For higher quality plots, other R packages like **tmap** should be used.

# Working with Projections

Projections is an important aspect of working with geospatial data. In order to process or analyze two or more sets of geospatial data, we first need to ensure that all of them are projected using the same coordinate system.

## Assigning EPSG code to a simple featured data frame

A common issue that can happen during importation of the data is that the coordinate system is missing or wrongly assigned during the process.

The `st_crs()` function can be used to display information on the coordinate system of an sf dataframe.

```{r}
st_crs(mpsz)
```

While `mpsz` appears to be projected in **svy21** as expected, the output shows that it using EPSG code **9001** instead of **3414**, which is the correct one for **svy21**. We can use the `st_set_crs()` function of sf to assign the correct EPSG code to `mpsz`. (as a new dataframe `mpsz3414`)

```{r}
mpsz3414 <- st_set_crs(mpsz, 3414)
```

Running `st_crs()` on `mpsz3414` confirms that the new dataframe has the correct EPSG code assigned.

```{r}
st_crs(mpsz3414)
```

## Transforming the projection of preschool from wgs84 to svy21

Geographic coordinate systems are not appropriate for geospatial analysis if the analysis requires distance or area measurements. Because of this, transforming data from geographic to projected coordinate systems is a common task.

The code block and output below shows that `preschool` is in the **wgs84** coordinate system.

```{r}
st_geometry(preschool)
```

Since reprojection is required, `st_transform()` from the sf package will be used. (`st_set_crs()` will not do the job) The following code chunk performs the reprojection into a new dataframe `preschool3414`.

```{r}
preschool3414 <- st_transform(preschool, 
                              crs = 3414)
```

Checking the contents confirms that `preschool3414` is now using the **svy21** projected coordinate system.

```{r}
#| echo: false
st_geometry(preschool3414)
```

# Importing and Converting Aspatial Data

Data that is not geospatial is called aspatial data. This data may capture location information in the form of x- and y-coordinates of the data points similar to `listings.csv` which comes from our final data source (AirBNB Singapore listings)

## Importing the aspatial data

The appropriate function from the **readr** package should be used depending on the file format. For csv files, the `read_csv()` function loads our file into a tibble dataframe named `listings`

```{r}
listings <- read_csv("data/aspatial/listings.csv")
```

The `list()` function from Base R displays the contents of the dataframe and also shows that there are 3540 rows and 75 columns.

```{r}
list(listings)
```

Scanning through the columns reveals that there are columns named `longitude` and `latitude` which appear to be in decimal degree format. We will assume that these are recorded based on the **wgs84** geographic coordinate system.

## Creating a simple feature from an aspatial data frame

We use the code chunk below to create an sf dataframe `listings_sf` from the aspatial data in `listings`.

```{r}
listings_sf <- st_as_sf(listings, 
                       coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
```

We used the following arguments in the above function call:

-   `coords` requires the column names of the x-coordinates followed by the y-coordinates

-   `crs` indicates the epsg format used in the data. EPSG 4326 corresponds to the wgs84 geographic coordinate system

-   `%>%` is used to nest st_transform() and transform the newly created sf dataframe into the svy21 coordinate system (EPSG 3414)

We can then use `glimpse()` on the new dataframe to examine the contents.

```{r}
glimpse(listings_sf)
```

The output shows that a new column `geometry` has been introduced in the data, while the coordinate columns `longitude` and `latitude` have been dropped.

# Geoprocessing with sf Package

Aside from data handling, the sf package also provides a range of geoprocessing or GIS analysis functions.

For this exercise, we work with two of these functions: buffering and point in polygon count.

## Buffering

**SCENARIO**

The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.

**SOLUTION**

First, use st_buffer() to compute a 5m buffer around the cycling paths

```{r}
buffer_cycling <- st_buffer(cyclingpath, 
                               dist=5, nQuadSegs = 30)
```

Second, calculate the areas of the buffers with `st_area()`.

```{r}
buffer_cycling$AREA <- st_area(buffer_cycling)
```

Last, summing the values of the new column using sum() will give the total land required.

```{r}
sum(buffer_cycling$AREA)
```

**Done! 2.2 million square meters are required**

## Point-in-polygon count

**SCENARIO 1**

A group wants to fund out the number of pre-schools in each planning subzone

**SOLUTION 1**

First, use `st_intersects` to identify preschools located in each planning subzone. (stored as a list) Then use `lengths()` from Base R to calculate the number of preschools in each planning subzone. This is stored in a new column `PreSch Count`

```{r}
mpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))
```

The new column can be summarized using `summary()` as shown. The output shows that the median number of preschools ranges from 0 to 72 and the median is 4.

```{r}
summary(mpsz3414$`PreSch Count`)
```

The planning subzones with the most number of preschools can be displayed using the `top_n()` function of the **dplyr** package. This shows that Tampines East has the maximum number of 72 preschools.

```{r}
top_n(mpsz3414, 1, `PreSch Count`)
```

**SCENARIO 2**

The group also wants to understand the density of preschools. Larger subzones are expected to have more preschools so density might be a more appropriate measure to compare

**SOLUTION 2**

We again use `st_area` to compute areas. This time we do this to compute for each subzone's.

```{r}
mpsz3414$Area <- mpsz3414 %>%
  st_area()
```

Next, the `mutate()` function from the dplyr package is used to compute the density

```{r}
mpsz3414 <- mpsz3414 %>%
  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)
```

The `top_n()` function can be used to fetch the subzone with the highest density, which is Cecil.

```{r}
top_n(mpsz3414, 1, `PreSch Density`)
```

# Exploratory Data Analysis (EDA)

For this exercise, we will learn of ggplot2 which can be used to create functional graphs for EDA purposes. We will just focus on `Presch Density` in this exercise.

We can generate a histogram using the conventional `hist()` function using the code below

```{r}
hist(mpsz3414$`PreSch Density`)
```

While it is convenient, it is far from being a publication-level quality visualization. There are some customizations available, but those are limited compared to more specialized packages'.

The code chunk below gives an example of what a histogram of the same data in **ggplot2** can look like.

```{r}
ggplot(data=mpsz3414, 
       aes(x= as.numeric(`PreSch Density`)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  labs(title = "Are pre-school even distributed in Singapore?",
       subtitle= "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",
      x = "Pre-school density (per km sq)",
      y = "Frequency")
```

This is clearly a step up and allows for a clearer and more impactful delivery of insights from the data.

**ggplot2** can also create other charts like scatterplots as shown below.

```{r}
ggplot(data=mpsz3414, 
       aes(y = `PreSch Count`, 
           x= as.numeric(`PreSch Density`)))+
  geom_point(color="black", 
             fill="light blue") +
  xlim(0, 40) +
  ylim(0, 40) +
  labs(title = "Preschool Density vs Preschool Count",
      x = "Pre-school density (per km sq)",
      y = "Pre-school count")
```
