---
title: "Geographic Segmentation wwith Spatially Constrained Clustering Techniques"
author: "Federico Jose Rodriguez"
date: "Sep 27 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
---

In this hands-on exercise, we apply hierarchical cluster analysis and spatially constrained cluster analysis to delineate homogeneous regions based on geographically referenced data.

This exercise is based on Chapter 12 of Dr Kam's online book which can be accessed [here](https://r4gdsa.netlify.app/ "R for Geospatial Data Science and Analytics by Dr Kam").

# Getting Started

## Analytical Question

In the development of spatial policy and for business, it is often important to segregate homogenous regions using multivariate data. We apply techniques in the study of Shan State in Myanmar by using various indicators.

## Data Sources

Data for this exercise are based on information for Myanmar and for its Shan state:

-   Myanmar township boundary data in ESRI shapefile format (polygon)

-   Shan state ICT indicators for 2014 contained in a csv file

## Installing and launching R packages

This exercise will make use of thirteen R packages:

-   **sf, rgdal, spdep -** for spatial data handling

-   **tidyverse -** collection of packages for performing data importation, wrangling and visualization

-   **tmap -** for plotting cartographic quality maps

-   **coorplot, ggpubr, heatmaply** - packages for multivariate data visualization and analysis

-   **cluster, ClustGeo** - packages for performing cluster analysis

The code chunk below uses `p_load()` of **pacman** package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.

```{r}
pacman::p_load(spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally)
```

We also define a random seed value for repeatability where of any randmoized results.

```{r}
set.seed(1234)
```

# Data Import and Preparation

## Data Loading - Shan state boundary

The code chunk below uses `st_read()` of the **sf** package to load the Myanmar township boundary shapefile into an R object. The code chunk includes a pipeline to already filter to the Shan state and include only the relevant columns.

```{r}
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "myanmar_township_boundaries") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)")) %>%
  select(c(2:7))
```

We can inspect the contents of shan_sf using the code chunk below

```{r}
shan_sf
```

The sf dataframe conforms to the tidy framework. Given this, we can also use `glimpse()` to reveal the fields' data types.

```{r}
glimpse(shan_sf)
```

## Data Loading - Shan state 2014 indicators (aspatial)

The code chunk below uses `read_csv()` to load the contents of the csv file into an object `ict`

```{r}
ict <- read_csv ("data/aspatial/Shan-ICT.csv")
```

We can use `head()` to check the first 6 elements of the object,

```{r}
head(ict)
```

and `summary()` to display summary statistics of the numeric columns.

```{r}
summary(ict)
```

The dataset contains 11 fields with 55 observations. The numeric fields give the total number of households in each township, and the number of households with the corresponding technology or appliance. (e.g., television, internet connection, etc)

## Deriving new indicator variables

Using the numeric fields directly will be highly biased as it depends on the number of households in the township. (i.e., townships with higher total households are likely to have higher values for all other columns) To overcome this problem, we can derive the penetration rates (PR) of each of the items by computing the number of households with that item per 1000 households. We accomplish this using `mutate()` from dplyr package in the code below.

```{r}
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 
```

We can use `summary()` again to display summary statistics on the 6 new columns.

```{r}
summary(ict_derived[c(12:17)])
```

## Joining spatial and aspatial data

For later map preparations, we need to combine the two datasets (geospatial `shan_sf`, aspatial `ict_derived`) into a single object. We do this using the `left_join()` function of the **dplyr** package. Both datasets have a common field `TS_PCODE` which will be treated as the unique identifier or joining key.

```{r}
shan_sf <- left_join(shan_sf, 
                     ict_derived, by=c("TS_PCODE"="TS_PCODE"))
  
write_rds(shan_sf, "data/rds/shan_sf.rds")
```

The code includes creation of a new rds file so we can use the following code in the future to read this joined dataset without performing all the steps above.

```{r}
shan_sf <- read_rds("data/rds/shan_sf.rds")
```

# Exploratory Data Analysis (EDA)

## EDA using statistical graphics

We can use histograms to visualize the overall distribution of data valuesâ€“ e.g., the shape or skewness. The code chunk below produces on for the field `RADIO_PR`.

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20,  color="black", fill="light blue") +
  xlab("Radio Penetration Rate, per K-HH") +
  ylab("No. of Townships")
```

We can also use boxplots for identifying the median, quartiles, and outliers in the data.

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_boxplot(color="black", 
               fill="light blue")+
  xlab("Radio Penetration Rate, per K-HH")
```

We can create multiple histograms side by side by creating objects for each variable's histogram, and then laying them out in a grid with `ggarange()` of the **ggpubr** package.

::: panel-tabset
#### Creation of Histogram objects

```{r}
radio <- ggplot(data=ict_derived, aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20,color="black", fill="light blue") +
  xlab("Radio PR") +
  ylab("No. of Townships")

tv <- ggplot(data=ict_derived, aes(x= `TV_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  xlab("TV PR") +
  ylab("No. of Townships")

llphone <- ggplot(data=ict_derived, aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  xlab("Landline Phone PR") +
  ylab("No. of Townships")

mphone <- ggplot(data=ict_derived, aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  xlab("Mobile Phone PR") +
  ylab("No. of Townships")

computer <- ggplot(data=ict_derived, aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  xlab("Computer PR") +
  ylab("No. of Townships")

internet <- ggplot(data=ict_derived, aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  xlab("Internet PR") +
  ylab("No. of Townships")
```

#### Grid display of multiple histograms

```{r}
ggarrange(radio, tv, llphone, mphone, computer, internet, 
          ncol = 3, nrow = 2)
```
:::

## EDA using choropleth map

The code chunk below prepares a choropleth map of the Shan state and the Radio penetration rate using `qtm()`

```{r}
qtm(shan_sf, "RADIO_PR")
```

The above map is based on the derived penetration rate. We can use choropleth maps to go back to the earliest statement that using the raw variables are likely to be biased on the number of households. We can use the code chunk below to look at them side by side. We use the approach of passing multiple arguments instead of using `tmap_arrange()`

```{r}
tm_shape(shan_sf) + 
  tm_fill(col = c("TT_HOUSEHOLDS", "RADIO"),
          n = 5,style = "jenks", 
          title = c("Total households","Number Radio")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.position = c("right", "top"), bg.color = "grey90")
```

The above map shows that townships with high number of households with radios, also are towns with the high number of households. We can produce a second map to see if the penetration rate and the total number of households are correlated.

```{r}
tm_shape(shan_sf) + 
  tm_fill(col = c("TT_HOUSEHOLDS", "RADIO_PR"),
          n = 5,style = "jenks", 
          title = c("Total households","Radio Penetration")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.position = c("right", "top"), bg.color = "grey90")
```

The second pair of maps shows no strong correlation between townships having high number of households and having high radio penetration rates.

Finally, we can show the six derived variables visually using a similar approach in the code chunk below. The viewer needs to be mindful of the data classes. While the darker the shading means a higher value for that derived variable, the range of values are different between pairs of variables.

```{r}
tm_shape(shan_sf) + 
  tm_fill(col = c("RADIO_PR", "TV_PR", "LLPHONE_PR",
                  "MPHONE_PR", "COMPUTER_PR", "INTERNET_PR"),
          n = 5,style = "jenks") + 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.position = c("right", "top"), bg.color = "grey90")
```

# Correlation Analysis

Before we perform cluster analysis, it is important to check that the cluster variables are not highly correlated.

In the code chunk below, we use `corrplot.mixed()` from the **corrplot** package to visualize the correlation between vairables

```{r}
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

The plot above shows that `COMPUTER_PR` and `INTERNET_PR` are highly correlated (coefficient of 0.87, shown as a very dark blue oval) This suggests that only one of these variables should be used in cluster analysis.

# Hierarchical Cluster Analysis

In this section, we perform hierarchical cluster analysis which is done in a few steps steps

## Selecting and extracting cluster variables

The code chunk below will be used to extract the clustering variables from the `shan_sf` dataframe. We have chosen to include `COMPUTER_PR` rather than `INTERNET_PR` for the cluster analysis

```{r}
cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

The next step is to change the row names or indices to the township names rather than the row numbers

```{r}
row.names(cluster_vars) <- cluster_vars$"TS.x"
head(cluster_vars,10)
```

We see that the row numbers have been replaced with the township names, however, the township names are now duplicated. We solve this by using the code chunk below

```{r}
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict, 10)
```

## Data standardisation

Multiple variables will usually have different range of values. If we use them as is for cluster analysis, then the clustering will be biased towards variables with larger values. It is useful to standardise the clustering variables to reduce the risk of this occuring.

### Min-max standardisation

The code chunk below uses `normalize()` of **heatmaply** package to standardise the clustering variables using min-max method. We then use `summary()` to show that the ranges of each variable have transformed to \[0,1\]

```{r}
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```

### Z-score standardisation

We can perform z-score standardisation by using `scale()` of **Base R**. We use `describe()` of **psych** package to display some statistics of the standardised columns. These show that each of the variables have been transformed to have a mean of 1 and a standard deviation of 1

```{r}
shan_ict.z <- scale(shan_ict)
describe(shan_ict.z)
```

### Visualising the standardised clustering variables

Aside from viewing the statistics of the standardised variables, it is also good practice to visualise their distribution graphically.

The code chunk below produces histograms to show the `RADIO_PR` field without and with standardisation

```{r}
r <- ggplot(data=ict_derived, aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

Alternatively, we can view these as density plots using the code below.

```{r}
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

## Computing the proximity matrix

xx
