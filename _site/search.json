[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "",
    "text": "Welcome to my website for my work in the course ISSS 626 - Geospatial Analytics and Applications during the August term of 2024 under Dr Kam Tin Seong.\nThe course covers theory and methods of geospatial analysis and the tools in R to implement such analyses."
  },
  {
    "objectID": "index.html#hands-on-exercises",
    "href": "index.html#hands-on-exercises",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "Hands-On Exercises",
    "text": "Hands-On Exercises\nHands-on exercises are assigned before each lesson to give us hands-on experience in using R on the geospatial analysis methods and functions we learned. We are given step-by-step instructions and explanations (through Dr Kam’s online book) which complement our pre-class reading, and prepares us for the in-class exercises.\n\nGeospatial Data Wrangling with R (for Session 1, 26 Aug ’24)\nChoropleth Mapping with R (for Session 1, 26 Aug ’24)\n1st Order Spatial Point Patterns Analysis Methods (for Session 2, 2 Sept ’24)\n2nd Order Spatial Point Patterns Analysis Methods (for Session 2, 2 Sept ’24)"
  },
  {
    "objectID": "index.html#in-class-exercises",
    "href": "index.html#in-class-exercises",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "In-Class Exercises",
    "text": "In-Class Exercises\nIn each session, we go through a hands-on exercise to revise the readings for the lesson. The objective of these is to further reinforce the concepts and tools learned in the readings and in the take-home exercise. These will also go further into the analysis and interpretation of results.\n\nIntroduction to Geospatial Analytics (26 Aug ’24)"
  },
  {
    "objectID": "index.html#take-home-exercises",
    "href": "index.html#take-home-exercises",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "Take Home Exercises",
    "text": "Take Home Exercises\nComing Soon"
  },
  {
    "objectID": "In-class/In-class_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "In-class/In-class_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Analytics w/ Derek",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Geospatial Data Wrangling with R",
    "section": "",
    "text": "For this hands-on exercise, we performed basic data wrangling tasks using the sf package in R.\nThis exercise is based on Chapter 1 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#data-sources",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#data-sources",
    "title": "Geospatial Data Wrangling with R",
    "section": "Data Sources",
    "text": "Data Sources\nThe exercise will use the following publicly available datasets:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nPre-Schools location from data.gov.sg\nCycling Path from LTA DataMall\nSingapore AirBNB listing data from Inside AirBNB\n\nThe files from the first three are loaded into a folder named geospatial, while the last one (AirBNB listings) is loaded into a folder named aspatial."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "title": "Geospatial Data Wrangling with R",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of two R packages: sf and tidyverse. Tidyverse is a family of R packages used for data wrangling and visualization. Sf is used for importing, managing and processing geospatial data.\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polygon-feature-data-in-shapefile-format",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing polygon feature data in shapefile format",
    "text": "Importing polygon feature data in shapefile format\nMP14_SUBZONE_WEB_PL is a polygon feature layer in ESRI shapefile format from the first data source. (Master Plan 2014 Subzone Boundary from data.gov.sg) This will get loaded into R as a polygon feature data frame.\nThe st_read() function call for ESRI shapefiles requires two arguments: dsn which defines the path, and layer which defines the shapefile name. The path only requires a folder and therefore does not require a file (with an extension) to be named. We load this data into a dataframe mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message confirms that the load is successful and that the objects are multipolygon features. It also gives information on the number of features (323), fields (15) and the coordinate system. (SVY21) The bounding box value defines the extent of the data."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polyline-feature-data-in-shapefile-format",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polyline-feature-data-in-shapefile-format",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing polyline feature data in shapefile format",
    "text": "Importing polyline feature data in shapefile format\nCyclingPath is a line feature layer in ESRI shapefile format from the third data source. (Cycling Path from LTA) This will get loaded into R as a line feature data frame.\nA similar function call is used to load the data into R as a dataframe cyclingpath.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message confirms the type (Multistring), the number of features (3138) and fields (2) among other information."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-gis-data-in-kml-format",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-gis-data-in-kml-format",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing GIS data in kml format",
    "text": "Importing GIS data in kml format\nPreSchoolsLocation is a point feature layer in kml format from the second data source. (Preschools Location from data.gov.sg)\nThe st_read() function call for KML files requires one parameter, which is the complete path, including the kml filename. We load this data into a dataframe preschool.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message confirms the type (Point), the number of features (2290) and fields (2) among other information."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Geospatial Data Wrangling with R",
    "section": "Working with st_geometry()",
    "text": "Working with st_geometry()\nThe geometry column in the sf dataframe is a list of class sfc which contains the geometries. The contents of the column can be retrieved by:\n\ncalling the column using mpsz$geometry , mpsz$geom , or mpsz[[1]]\nusing the function st_geometry()\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Geospatial Data Wrangling with R",
    "section": "Working with glimpse()",
    "text": "Working with glimpse()\nThe glimpse() function from dplyr reveals the data type of each field and gives the first few observations.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Geospatial Data Wrangling with R",
    "section": "Working with head()",
    "text": "Working with head()\nThe Base R head() function reveals the first elements of the dataframe. The number of elements can be set by specifying an n argument. It also displays information for an sf dataframe like the geometry type, bounding box and projection system.\n\nhead(mpsz, n = 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-featured-data-frame",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-featured-data-frame",
    "title": "Geospatial Data Wrangling with R",
    "section": "Assigning EPSG code to a simple featured data frame",
    "text": "Assigning EPSG code to a simple featured data frame\nA common issue that can happen during importation of the data is that the coordinate system is missing or wrongly assigned during the process.\nThe st_crs() function can be used to display information on the coordinate system of an sf dataframe.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile mpsz appears to be projected in svy21 as expected, the output shows that it using EPSG code 9001 instead of 3414, which is the correct one for svy21. We can use the st_set_crs() function of sf to assign the correct EPSG code to mpsz. (as a new dataframe mpsz3414)\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nRunning st_crs() on mpsz3414 confirms that the new dataframe has the correct EPSG code assigned.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Geospatial Data Wrangling with R",
    "section": "Transforming the projection of preschool from wgs84 to svy21",
    "text": "Transforming the projection of preschool from wgs84 to svy21\nGeographic coordinate systems are not appropriate for geospatial analysis if the analysis requires distance or area measurements. Because of this, transforming data from geographic to projected coordinate systems is a common task.\nThe code block and output below shows that preschool is in the wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nSince reprojection is required, st_transform() from the sf package will be used. (st_set_crs() will not do the job) The following code chunk performs the reprojection into a new dataframe preschool3414.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nChecking the contents confirms that preschool3414 is now using the svy21 projected coordinate system.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing the aspatial data",
    "text": "Importing the aspatial data\nThe appropriate function from the readr package should be used depending on the file format. For csv files, the read_csv() function loads our file into a tibble dataframe named listings\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe list() function from Base R displays the contents of the dataframe and also shows that there are 3540 rows and 75 columns.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nScanning through the columns reveals that there are columns named longitude and latitude which appear to be in decimal degree format. We will assume that these are recorded based on the wgs84 geographic coordinate system."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-from-an-aspatial-data-frame",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-from-an-aspatial-data-frame",
    "title": "Geospatial Data Wrangling with R",
    "section": "Creating a simple feature from an aspatial data frame",
    "text": "Creating a simple feature from an aspatial data frame\nWe use the code chunk below to create an sf dataframe listings_sf from the aspatial data in listings.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe used the following arguments in the above function call:\n\ncoords requires the column names of the x-coordinates followed by the y-coordinates\ncrs indicates the epsg format used in the data. EPSG 4326 corresponds to the wgs84 geographic coordinate system\n%&gt;% is used to nest st_transform() and transform the newly created sf dataframe into the svy21 coordinate system (EPSG 3414)\n\nWe can then use glimpse() on the new dataframe to examine the contents.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nThe output shows that a new column geometry has been introduced in the data, while the coordinate columns longitude and latitude have been dropped."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\nSCENARIO\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nSOLUTION\nFirst, use st_buffer() to compute a 5m buffer around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nSecond, calculate the areas of the buffers with st_area().\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLast, summing the values of the new column using sum() will give the total land required.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nDone! 2.2 million square meters are required"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Geospatial Data Wrangling with R",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\nSCENARIO 1\nA group wants to fund out the number of pre-schools in each planning subzone\nSOLUTION 1\nFirst, use st_intersects to identify preschools located in each planning subzone. (stored as a list) Then use lengths() from Base R to calculate the number of preschools in each planning subzone. This is stored in a new column PreSch Count\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThe new column can be summarized using summary() as shown. The output shows that the median number of preschools ranges from 0 to 72 and the median is 4.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nThe planning subzones with the most number of preschools can be displayed using the top_n() function of the dplyr package. This shows that Tampines East has the maximum number of 72 preschools.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nSCENARIO 2\nThe group also wants to understand the density of preschools. Larger subzones are expected to have more preschools so density might be a more appropriate measure to compare\nSOLUTION 2\nWe again use st_area to compute areas. This time we do this to compute for each subzone’s.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, the mutate() function from the dplyr package is used to compute the density\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nThe top_n() function can be used to fetch the subzone with the highest density, which is Cecil.\n\ntop_n(mpsz3414, 1, `PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            Area   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there! I’m Derek (Federico Jose Rodriguez) and I built this website as I started taking my Geospatial Analytics and Applications course in the MITB Program of Singapore Management University in 2024."
  },
  {
    "objectID": "about.html#about-me-and-this-site",
    "href": "about.html#about-me-and-this-site",
    "title": "About",
    "section": "",
    "text": "Hi there! I’m Derek (Federico Jose Rodriguez) and I built this website as I started taking my Geospatial Analytics and Applications course in the MITB Program of Singapore Management University in 2024."
  },
  {
    "objectID": "about.html#quarto-websites",
    "href": "about.html#quarto-websites",
    "title": "About",
    "section": "Quarto Websites",
    "text": "Quarto Websites\nThis is a Quarto website.\nTo learn more about Quarto websites and start creating your own, please visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html",
    "title": "Choropleth Mapping with R",
    "section": "",
    "text": "For this hands-on exercise, we learned how to plot choropleth maps by using an R package called tmap\nThis exercise is based on Chapter 2 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-sources",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-sources",
    "title": "Choropleth Mapping with R",
    "section": "Data Sources",
    "text": "Data Sources\nThe exercise will use the following publicly available datasets:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 from singstat.gov\n\nThe first one is geospatial data and was also used in the previous hands-on exercise. The second source is for aspatial data but the PA and SZ fields in it allows geocoding into the shapefile."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#installing-and-launching-r-packages",
    "title": "Choropleth Mapping with R",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of three R packages: sf, tidyverse and tmap. We have already introduced the first two in the last exercise: tidyverse is a family of R packages used for data wrangling and visualization, while sf is used for importing, managing and processing geospatial data. Tidyverse is made up of multiple packages which include tidyr and dplyr which will be the specific packages where the functions we use will come from.\nTmap stands for thematic map and will enable us to create the functional choropleth maps that go beyond the capabilities of plot()\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap)\ntmap_options(show.messages = FALSE)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-geospatial-data-into-r",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-geospatial-data-into-r",
    "title": "Choropleth Mapping with R",
    "section": "Importing Geospatial Data into R",
    "text": "Importing Geospatial Data into R\nWe first import MP14_SUBZONE_WEB_PL using st_read() function by providing the path and the layer name as parameters.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can examine the contents by calling the dataframe like in the code chunk below. This function call only shows the first 10 features or rows of the dataframe.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-attribute-data-into-r",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-attribute-data-into-r",
    "title": "Choropleth Mapping with R",
    "section": "Importing Attribute Data into R",
    "text": "Importing Attribute Data into R\nOur remaining data is in a csv file which we will load into a dataframe called popdata using read_csv() which comes from the readr package that is included in tidyverse.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can quickly examine the data by calling the dataframe name. This shows that popdata consists of 738K records or rows with 7 attributes or columns.\n\npopdata\n\n# A tibble: 738,492 × 7\n   PA         SZ                     AG     Sex     FA              Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &lt;= 60             0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;60 to 80        10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;80 to 100       30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;100 to 120      80  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;120             20  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Not Available     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &lt;= 60             0  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;60 to 80        10  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;80 to 100       40  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;100 to 120      90  2011\n# ℹ 738,482 more rows\n\n\nWe will use the 2020 information from this to build a new data table popdata2020 which includes the following variables:\n\nPA and SZ give information on the location (planning area and township)\nYOUNG is the population for those aged 0 to 24\nECONOMY ACTIVE is the population for those aged 25 to 64\nAGED is the population for those aged 65 and above\nTOTAL is the total population across all age groups\nDEPENDENCY is the ratio between young and aged against the economy active group"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-wrangling",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-wrangling",
    "title": "Choropleth Mapping with R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nTo generate the required table from popdata, we will use pivot_wider() of tidyr package, mutate(), filter(), group_by() and select() of dplyr package. All of these are included in tidyverse.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nWe can check that the transformation has been executed properly by displaying the new dataframe.\n\npopdata2020\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Cen…  1440             2640   770  4850      0.837\n 2 Ang Mo Kio Cheng San             6660            15380  6080 28120      0.828\n 3 Ang Mo Kio Chong Boon            6150            13970  6450 26570      0.902\n 4 Ang Mo Kio Kebun Bahru           5500            12040  5080 22620      0.879\n 5 Ang Mo Kio Sembawang Hills       2130             3390  1270  6790      1.00 \n 6 Ang Mo Kio Shangri-La            3970             8430  3540 15940      0.891\n 7 Ang Mo Kio Tagore                2220             4160  1520  7900      0.899\n 8 Ang Mo Kio Townsville            4720            11430  5050 21200      0.855\n 9 Ang Mo Kio Yio Chu Kang             0                0     0     0    NaN    \n10 Ang Mo Kio Yio Chu Kang East     1190             2230   740  4160      0.865\n# ℹ 322 more rows"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#joining-the-attribute-and-geospatial-data",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#joining-the-attribute-and-geospatial-data",
    "title": "Choropleth Mapping with R",
    "section": "Joining the attribute and geospatial data",
    "text": "Joining the attribute and geospatial data\nTo use this attribute data for our analysis, we need to join it with the geospatial data. The first step will be to convert the PA and SZ values to uppercase to make sure that they follow the same convention as the geospatial data. We use the mutate_at() function to apply this transformation.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThe next step is to use left_join() from dplyr to merge the two tables using SZ.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nAs the left side is an sf dataframe, the resulting object is also an sf dataframe and we write this into a file to store for future use without rerunning all the transformations so far.\n\nwrite_rds(mpsz_pop2020, \"data/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#plotting-a-choropleth-map-quickly-using-qtm",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#plotting-a-choropleth-map-quickly-using-qtm",
    "title": "Choropleth Mapping with R",
    "section": "Plotting a choropleth map quickly using qtm()",
    "text": "Plotting a choropleth map quickly using qtm()\nqtm() is a convenient way to produce a thematic or choropleth map. It provides a good default or initial visualization.\nThe code chunk below draws a standard choropleth map using the values from DEPENDENCY as the fill.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode(\"plot\") produces a static plot. To produce an interactive plot, tmap_mode(\"view\") should be used instead.\nqtm() takes the sf dataframe as its first argument. The fill argument defines which attribute to map."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Choropleth Mapping with R",
    "section": "Creating a choropleth map by using tmap’s elements",
    "text": "Creating a choropleth map by using tmap’s elements\nWhile convenient, the downside of qtm() is that it makes controlling the aesthetics of individual layers harder to control. Using tmap’s drawing elements allows more customization, and allows the production of higher quality maps.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nWe go through the different elements plotted and the respective functions below.\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elements.\nIn the code chunk below, tm_shape() is used to define the input data and then tm_polygons() draws the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nThe code chunk below generates a choropleth map of the dependency ratio by planning subzone by passing DEPENDENCY to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nA few points on tm_polygons():\n\nThe default binning used is called “pretty”. We will go more into data classification methods later\nThe default color scheme is YlOrRd (Yellow Orange Red) of ColorBrewer. We will also go more into color schemes later\nBy default, missing values are shaded grey\n\n\n\nDrawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is actually a wrapper of two other functions: tm_fill() and tm_border().\ntm_fill() shades the polygons using the default color scheme. The code chunk below draws the choropleth map with just this element.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_borders() adds the borders of the shapefile onto the map. We add this element to the previous code to produce a similar plot to the one generated with tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\ntm_borders() has the following (optional) arguments:\n\nalpha defines the transparency and takes a value of 0 (totally transparent) to 1 (totally opaque)\ncol defines the border colour\nlwd defines the border line width (default 1)\nlty defines the border line type (default solid)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-classification-methods-on-tmap",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-classification-methods-on-tmap",
    "title": "Choropleth Mapping with R",
    "section": "Data Classification Methods on tmap",
    "text": "Data Classification Methods on tmap\nData classification refers to grouping (a large number of) observations into data ranges or classes. tmap provides ten data classification methods which include: fixed, sd, equal, pretty, quantile, kmeans, hclust, bclust, fisher, and jenks\nThe data classification method can be defined by using the style argument in tm_fill() or tm_polygons()\n\nPlotting choropleth maps with built-in classification methods\nThe code below produces a plot using quantile data classification with 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code below produces a plot using equal data classification with 5 classes. Note that the previous chart produces evenly distributed classes, while this new chart has almost all but one zone in the first class.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code below produces a plot using jenks data classification. By changing the style argument, the other data classification methods can be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nPlotting Choropleth Maps with custom break\nThe builtin styles compute the class breaks or boundaries internally. To override this, the breakpoints can be set explicitly using the breaks argument of tm_fill()\nThe breaks defined will include the minimum and maximum. Therefore, to define n classes, n+1 breakpoints should be defined in the breaks argument.\nWe first run some descriptive statistics on DEPENDENCY before we define the breakpoints\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.7113  0.7926  0.8561  0.8786 19.0000      92 \n\n\nBased on the distribution, say we define the breakpoints for five classes to be 0.6, 0.7, 0.8 and 0.9 to split. We need to include a minimum, 0, and a maximum, 20, for the breaks argument.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 20)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#colour-schemes",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#colour-schemes",
    "title": "Choropleth Mapping with R",
    "section": "Colour Schemes",
    "text": "Colour Schemes\ntmap supports user-defined colour maps, and pre-defined colour maps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour map, we assign a value to the palette argument of tm_fill() as shown in the code below\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe choropleth map is shaded in blue where a darker shade corresponds to a higher value of DEPENDENCY. To reverse this behavior, we can add a “-” prefix to the passed value.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#map-layouts",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#map-layouts",
    "title": "Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\nMap layout refers to the combination of all map elements into a cohesive map. Aside from the objects, the other elements include the title, the scale bar, a compass, margins and aspect ratios.\n\nMap Legend\nSeveral options are provided to adjust the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMap Style\nA wide variety of layout settings can be changed by calling tmap_style()\nThe codeblock below shows the map using the classic style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\ntmap provides options to add other elements like a compass, scale, and grid lines. In the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add these elements.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nNote that the above map still uses the classic style. To revert to the default style, use the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#drawing-small-multiple-choropleth-maps",
    "title": "Choropleth Mapping with R",
    "section": "Drawing Small Multiple Choropleth Maps",
    "text": "Drawing Small Multiple Choropleth Maps\nSmall multiple maps or facet maps are composed of multiple maps arranged side-by-side. (in a grid, stacked vertically, lined up) Small multiple maps allow visualization of how spatial relationships change with respect to one variable. (e.g., time)\nThere are three ways to define small multiples in tmap:\n\nby assigning multiple values to at least one aesthetic argument,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange()\n\n\nAssigning multiple values to at least one of the aesthetic arguments\nIn the code below, small multiple maps are created by passing a list of (numeric) columns as the col argument of tm_fill() Each map depicts a different column or attribute.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn the next code, two parameters are passed to palette argument to result to different colour maps for the each small multiple.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nIn the code below, a small multiple of each region is created by using tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nBy creating multiple stand-alone maps and using tmap_arrange()\nIn the following code, two maps are defined individually and then displayed side by side using tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#mapping-spatial-objects-meeting-selection-criterion",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#mapping-spatial-objects-meeting-selection-criterion",
    "title": "Choropleth Mapping with R",
    "section": "Mapping Spatial Objects Meeting Selection Criterion",
    "text": "Mapping Spatial Objects Meeting Selection Criterion\nInstead of using small multiples to look at a particular subset of the data, you can also use a selection criteria or a mask to only map objects meeting a particular condition. The code below produces a map for only the Central Region.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "The exercise uses the following data sources:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg in SHP and KML formats\nMaster Plan 2019 Subzone Boundary from data.gov.sg\nPre-school locations from data.gov.sg\nSingapore 2023 population from singstat.gov.sg\n\n\n\n\nThis exercise will make use of four R packages: sf, tidyverse, ggstatsplot and tmap.\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, ggstatsplot)\n\n\n\n\nThe code chunk below loads the Masterplan subzone boundary shape file as a dataframe mpsz14_shp\n\nmpsz14_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe code chunk below loads the Masterplan subzone boundary KML file as a dataframe mpsz14_kml\n\nmpsz14_kml = st_read(\"data/geospatial/MasterPlan2014SubzoneBoundary.kml\")\n\nRunning the code shows that the data is likely corrupted as it is not being properly loaded into R. To illustrate loading the same data in KML format, we can create a clean KML file using st_write()\n\nst_write(mpsz14_shp,\n         \"data/geospatial/MP14SubzoneBoundary.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/geospatial/MP14SubzoneBoundary.kml' using driver `KML'\nWriting layer `MP14SubzoneBoundary' to data source \n  `data/geospatial/MP14SubzoneBoundary.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\nmpsz14_kml = st_read(\"data/geospatial/MP14SubzoneBoundary.kml\")\n\nReading layer `MP14SubzoneBoundary' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MP14SubzoneBoundary.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the 2019 Masterplan subzone boundary SHP file as a dataframe mpsz19_shp\n\nmpsz19_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe output shows that the data uses a geographic coordinate system instead of a projected coordinate system that we need for analysis. This needs to be translated before we can analyze this data with our other datasets. To do this, we can revise the code to:\n\nmpsz19_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the KML file and also shows we have it in geographic coordinate system.\n\nmpsz19_kml = st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\nWe load the 2023 population data into a dataframe called popdata and see that there are 101K rows and 7 columns.\n\npopdata = read_csv(\"data/aspatial/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nxxx\nxxx\nxxx\nxxx"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#data-sources",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#data-sources",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "The exercise uses the following data sources:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg in SHP and KML formats\nMaster Plan 2019 Subzone Boundary from data.gov.sg\nPre-school locations from data.gov.sg\nSingapore 2023 population from singstat.gov.sg"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#installing-and-launching-r-packages",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#installing-and-launching-r-packages",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "This exercise will make use of four R packages: sf, tidyverse, ggstatsplot and tmap.\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#importing-the-geospatial-data",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#importing-the-geospatial-data",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "The code chunk below loads the Masterplan subzone boundary shape file as a dataframe mpsz14_shp\n\nmpsz14_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe code chunk below loads the Masterplan subzone boundary KML file as a dataframe mpsz14_kml\n\nmpsz14_kml = st_read(\"data/geospatial/MasterPlan2014SubzoneBoundary.kml\")\n\nRunning the code shows that the data is likely corrupted as it is not being properly loaded into R. To illustrate loading the same data in KML format, we can create a clean KML file using st_write()\n\nst_write(mpsz14_shp,\n         \"data/geospatial/MP14SubzoneBoundary.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/geospatial/MP14SubzoneBoundary.kml' using driver `KML'\nWriting layer `MP14SubzoneBoundary' to data source \n  `data/geospatial/MP14SubzoneBoundary.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\nmpsz14_kml = st_read(\"data/geospatial/MP14SubzoneBoundary.kml\")\n\nReading layer `MP14SubzoneBoundary' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MP14SubzoneBoundary.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the 2019 Masterplan subzone boundary SHP file as a dataframe mpsz19_shp\n\nmpsz19_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe output shows that the data uses a geographic coordinate system instead of a projected coordinate system that we need for analysis. This needs to be translated before we can analyze this data with our other datasets. To do this, we can revise the code to:\n\nmpsz19_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the KML file and also shows we have it in geographic coordinate system.\n\nmpsz19_kml = st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#importing-aspatial-data",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#importing-aspatial-data",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "We load the 2023 population data into a dataframe called popdata and see that there are 101K rows and 7 columns.\n\npopdata = read_csv(\"data/aspatial/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nxxx\nxxx\nxxx\nxxx"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "",
    "text": "For this hands-on exercise, we start learning about Spatial Point pattern analysis, starting with First Order effects. (based on an underlying property or location)\nWe will be using the functions of the spatstat package, and applying it to an analysis on the location of childcare centres in Singapore."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#data-sources",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#data-sources",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Data Sources",
    "text": "Data Sources\nData for this exercise are from public sources and include:\n\nLocation and attribute information of childcare centres in Singapore from data.gov.sg\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nNational boundary of Singapore provided in SLA and ESRI shapefile format"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#installing-and-launching-r-packages",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of five R packages: sf, tidyverse, spatstat, raster, maptools and tmap. Among these, the new ones we are using are:\n\nspatstat - offers a wide range of functions for point pattern analysis (PPA)\nraster - used to read, write, manipulate and analyse models of gridded spatial data\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, spatstat, raster)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#importing-the-geospatial-data",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#importing-the-geospatial-data",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Importing the Geospatial Data",
    "text": "Importing the Geospatial Data"
  }
]