[
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "",
    "text": "(Summary here. WIP)"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.1-background",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.1-background",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "A.1 Background",
    "text": "A.1 Background\nRoad traffic accidents account for 1.19million deaths and up to 50 million non-fatal injuries according to a report by the WHO last year.\nThe same report identifies major risk groups: low- and middle-income countries, (esp in Africa and Europe) the working population, and males. It also identifies some key risk factors which include human error, speeding, driving under the influence of alcohol, distracted driving, unsafe road infrastructure, unsafe vehicles, and law enforcement. Most of the factors identified are behavioral in nature but do not discount that other factors may also contribute to a higher risk of occurrence.\nWithin Southeast Asia, Thailand has ranked the highest in terms of incidence of road traffic accidents with an average number of of 20,000 deaths a year or 56 a day. The country has also seen an increase in the number of accidents from 2014 to 2021. A large 19% of these accidents occurred in national highways, and the chances of encountering an accident-prone zone was found to be 66%."
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.2-objectives",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.2-objectives",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "A.2 Objectives",
    "text": "A.2 Objectives\nThis study aims to take a deeper look into the road accidents in Thailand, focusing on the Bangkok Metropolitan Region (BMR) which contains the capital Bangkok, and five neighboring provinces. (Nonthaburi, Nakhon Pathom, Pathum Thani, Samut Prakan, Samut Sakhon)\nAs most literature has focused on behavioral and environmental factors, the study will focus on identifying spatiotemporal factors influencing the occurrence of road accidents in BMR. At the minimum, the study deliverables include the following:\n\nVisualization of spatiotemporal dynamics of road traffic accidents in BMR\nDetailed spatial analysis of road traffic accidents in BMR\nDetailed spatiotemporal analysis of road traffic accidents in BMR\n\nThe appropriate technique must be used for these deliverables and all the analysis and visualizations will be carried out using R."
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.3-data-sources",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.3-data-sources",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "A.3 Data Sources",
    "text": "A.3 Data Sources\nThe study makes use of the following datasets which are publicly available online.\n\n\n\nDataset Short Name\nDescription\nDatasource\n\n\n\n\nTHRA\nThailand road accident data from 2019 to 2022\nKaggle\n\n\nTHOSM\nThailand roads open street map in shapefile format\nHDX\n\n\nTHSAB\nThailand - Subnational Administrative Boudaries shapefile\nHDX"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.4-importing-and-launching-r-packages",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#a.4-importing-and-launching-r-packages",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "A.4 Importing and Launching R Packages",
    "text": "A.4 Importing and Launching R Packages\nFor this study, four R packages will be used. A description of the packages and the code, using p_load() of the pacman package, to import them is given below.\n\nPackage DescriptionImport Code\n\n\nThe loaded packages include:\n\nsf - package for importing, managing and processing vector-based geospatial data\ntidyverse - collection of packages for performing data importation, wrangling and visualization\ntmap - package with functions for plotting cartographic quality maps\nsPNetwork - provides functions for performing SPPA methods like KDE and K-function on a network. The package can also be used to build spatial matrices to conduct traditional spatial analyses with spatial weights based on reticular distances\nspatstat - package for plotting, EDA and simulation of spatial data\n\n\n\n\npacman::p_load(sf, spNetwork, tmap, tidyverse, spatstat)\n\n\n\n\nAs we will be performing simulations in the analysis later, it is good practice to define a random seed to be used so that results are consistent for viewers of this report, and the results can be reproduced.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.1-thailand-subnational-administrative-boundary-shapefile",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.1-thailand-subnational-administrative-boundary-shapefile",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.1 Thailand Subnational Administrative Boundary, Shapefile",
    "text": "B.1 Thailand Subnational Administrative Boundary, Shapefile\nWe load the Thailand subnational administrative boundary shapefile into an R dataframe using st_read() from the sf package. The source provides the geospatial data in varying levels as indicated by their suffix: country (0), province (1), district (2), and sub-district. (3) For focusing on the BMR, which covers Bangkok and neighboring provinces, province is the most likely level of detail we will need so we will use the code chunk below to load the appropriate layer first.\n\nthsab_prov &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Take-home\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nWe examine the loaded data to confirm the load has been done properly and to get some initial observations of the data.\n\nCalling ObjectChecking crs information with st_crs()\n\n\n\nthsab_prov\n\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   Shape_Leng Shape_Area                  ADM1_EN       ADM1_TH ADM1_PCODE\n1    2.417227 0.13133873                  Bangkok  กรุงเทพมหานคร       TH10\n2    1.695100 0.07926199             Samut Prakan    สมุทรปราการ       TH11\n3    1.251111 0.05323766               Nonthaburi         นนทบุรี       TH12\n4    1.884945 0.12698345             Pathum Thani        ปทุมธานี       TH13\n5    3.041716 0.21393797 Phra Nakhon Si Ayutthaya พระนครศรีอยุธยา       TH14\n6    1.739908 0.07920961                Ang Thong        อ่างทอง       TH15\n7    5.693342 0.54578838                 Lop Buri          ลพบุรี       TH16\n8    1.778326 0.06872655                Sing Buri         สิงห์บุรี       TH17\n9    2.896316 0.20907828                 Chai Nat         ชัยนาท       TH18\n10   4.766446 0.29208711                 Saraburi         สระบุรี       TH19\n   ADM1_REF ADM1ALT1EN ADM1ALT2EN ADM1ALT1TH ADM1ALT2TH  ADM0_EN   ADM0_TH\n1      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n2      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n3      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n4      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n5      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n6      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n7      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n8      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n9      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n10     &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n   ADM0_PCODE       date    validOn    validTo                       geometry\n1          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.6139 13...\n2          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.7306 13...\n3          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3415 14...\n4          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.8916 14...\n5          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.5131 14...\n6          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3332 14...\n7          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((101.3453 15...\n8          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3691 15...\n9          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.1199 15...\n10         TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((101.3994 15...\n\n\n\n\n\nst_crs(thsab_prov)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\nThe output confirms that we have a multipolygon sf object with 77 rows and 17 columns. There is a column named ADM1_EN which appears to contain the province names needed to define the BMR boundaries. It also shows that the dataset is using a coordinate reference system rather than a projected reference system.\nFirst, we reload the data to use a projected reference system and apply the correct reference system with EPSG code of 32647 using st_transform(). This transformation can be confirmed with st_crs() The tmap package is then used to visualize the object to see if it properly depicts the boundaries of Thailand and its provinces.\n\nLoad Object and Transform CRS informationChecking crs information with st_crs()Plot of thsab_prov using tmap\n\n\n\nthsab_prov &lt;- st_read(dsn=\"data/geospatial\",\n                          layer=\"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Take-home\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n\n\nst_crs(thsab_prov)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\n\ntm_shape(thsab_prov) +\n  tm_polygons(\"grey\")"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.2-filtering-thsab-for-the-bangkok-metropolitan-region",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.2-filtering-thsab-for-the-bangkok-metropolitan-region",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.2 Filtering THSAB for the Bangkok Metropolitan Region",
    "text": "B.2 Filtering THSAB for the Bangkok Metropolitan Region\nBefore further analyzing the data, we will limit the scope to only consider the Bangkok Metropolitan Region or BMR. This would encompass Bangkok, Nonthaburi, Nakhon Pathom, Pathum Thani, Samut Prakan, Samut Sakhon. While it is good to get insights outside of BMR, it is out of the study scope and it is best to focus on the objectives.\nThe code chunk below checks if all the provinces in the BMR appear as is under the ADM1_EN column of thsab_prov\n\nfilter(thsab_prov, ADM1_EN %in% c(\"Bangkok\", \"Nonthaburi\",\"Nakhon Pathom\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))$ADM1_EN\n\n[1] \"Bangkok\"       \"Samut Prakan\"  \"Nonthaburi\"    \"Pathum Thani\" \n[5] \"Nakhon Pathom\" \"Samut Sakhon\" \n\n\nWith the previous code returning all 6 provinces, we have confirmation that the provinces are all present and spelled as is in the data source. We create a new object bmr_boundary to contain only the provinces in BMR. We also take this opportunity to only keep the relevant columns in the dataset using the select() function of dplyr package.\n\nCreate BMR boundary object using filter()Plot of bmr_boundary using tmap\n\n\n\nbmr_boundary &lt;- st_read(dsn=\"data/geospatial\",\n                      layer=\"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nonthaburi\",\"Nakhon Pathom\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\")) %&gt;% dplyr::select(Shape_Leng, Shape_Area, ADM1_EN, geometry)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Take-home\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\n\n\ntm_shape(bmr_boundary) +\n  tm_polygons(\"grey\")\n\n\n\n\n\n\n\n\n\n\n\nThe code below creates a second object which is just a union of all the provinces. (i.e., borders between provinces are lost) This is done using the st_union() function.\n\nbmr_full = st_union(bmr_boundary)\n\n\ntm_shape(bmr_full) +\n  tm_polygons(\"grey\")\n\n\n\n\n\n\n\n\nThe code below keeps the final boundary objects into files to make loading more convenient for later analyses.\n\nwrite_rds(bmr_boundary, \"data/rds/bmr_boundary.rds\")\nwrite_rds(bmr_full, \"data/rds/bmr_full.rds\")\n\nThe code below then reloads the same objects into R:\n\nbmr_boundary = read_rds(\"data/rds/bmr_boundary.rds\")\nbmr_full = read_rds(\"data/rds/bmr_full.rds\")"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.3-road-accident-data-aspatial-csv-file",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.3-road-accident-data-aspatial-csv-file",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.3 Road Accident Data, Aspatial, csv-file",
    "text": "B.3 Road Accident Data, Aspatial, csv-file\nThe road accident data is contained in a csv file. We use the code block in the first tab below to load it into the thra object with some necessary transformations that we identified upon inspecting the raw file. The second tab gives an explanation of the different nested functions used in the code\nCode to import and transform road accident data\n\nbmracc &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")  %&gt;%\n  filter(!is.na(longitude) & longitude != \"\", \n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbmracc &lt;- filter(bmracc, geometry %in% st_intersection(bmr_full, bmracc)) %&gt;%\n  mutate(Year = year(incident_datetime)) %&gt;%\n  mutate(MonthNum = month(incident_datetime)) %&gt;%\n  mutate(Month = month(incident_datetime, label = TRUE, abbr = TRUE)) %&gt;%\n  mutate(DayOfWeek = wday(incident_datetime, label = TRUE, abbr = TRUE))\n\nCalling the new object shows that it has 12,989 rows across 20 fields.\n\nbmracc\n\nSimple feature collection with 12989 features and 20 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 12,989 × 21\n   acc_code incident_datetime   report_datetime     province_th  province_en  \n *    &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;        &lt;chr&gt;        \n 1   571882 2019-01-01 02:25:00 2019-01-02 17:32:00 นครปฐม       Nakhon Pathom\n 2   600001 2019-01-01 03:00:00 2019-01-05 10:33:00 นนทบุรี        Nonthaburi   \n 3   605043 2019-01-01 03:00:00 2019-03-29 08:22:00 สมุทรปราการ   Samut Prakan \n 4   629691 2019-01-01 03:05:00 2019-01-01 03:05:00 กรุงเทพมหานคร Bangkok      \n 5   571887 2019-01-01 04:30:00 2019-01-02 17:32:00 นครปฐม       Nakhon Pathom\n 6   599234 2019-01-01 04:45:00 2019-01-02 08:28:00 สมุทรปราการ   Samut Prakan \n 7   599990 2019-01-01 05:30:00 2019-01-05 10:35:00 สมุทรสาคร     Samut Sakhon \n 8   612045 2019-01-01 05:30:00 2019-10-09 13:50:00 นนทบุรี        Nonthaburi   \n 9   629689 2019-01-01 05:42:00 2019-01-01 05:42:00 กรุงเทพมหานคร Bangkok      \n10   607046 2019-01-01 06:30:00 2019-05-15 13:24:00 ปทุมธานี       Pathum Thani \n# ℹ 12,979 more rows\n# ℹ 16 more variables: agency &lt;chr&gt;, route &lt;chr&gt;, vehicle_type &lt;chr&gt;,\n#   presumed_cause &lt;chr&gt;, accident_type &lt;chr&gt;,\n#   number_of_vehicles_involved &lt;dbl&gt;, number_of_fatalities &lt;dbl&gt;,\n#   number_of_injuries &lt;dbl&gt;, weather_condition &lt;chr&gt;, road_description &lt;chr&gt;,\n#   slope_description &lt;chr&gt;, geometry &lt;POINT [m]&gt;, Year &lt;dbl&gt;, MonthNum &lt;dbl&gt;,\n#   Month &lt;ord&gt;, DayOfWeek &lt;ord&gt;\n\n\nWe use the code chunks below to check the data and visualize the data on the BMR boundary map.\n\ntm_shape(bmr_boundary) +\n  tm_polygons(col = \"grey\") +\n  tm_shape(bmracc) +\n  tm_dots(col = \"red\", size = 0.01, alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below writes the resulting accident dataset into an rds file for convenient loading.\n\nwrite_rds(bmracc, \"data/rds/bmracc.rds\")"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.4-thosm-thailand-roads-open-streetmap-shapefile",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.4-thosm-thailand-roads-open-streetmap-shapefile",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.4 THOSM (Thailand Roads Open StreetMap, Shapefile)",
    "text": "B.4 THOSM (Thailand Roads Open StreetMap, Shapefile)\nThe second geospatial object is the street map shapefile. We will use the object network to contain the final road network for the study.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                      layer=\"hotosm_tha_roads_lines_shp\")\n\nRunning the above code confirms that the dataset is in multilinestring sf format and that it contains 2.8M records across 15 variables. It also shows that there is no CRS applied to the dataset.\nBased on these, the following steps need to be done: apply the right CRS/EPSG code of 32647 or the same as bmr_full, and, filter the network to only include BMR.\nThe code below does the first step of applying a reference system and updating the EPSG code to 32647 using st_set_crs() and st_crs() from the sf package.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                      layer=\"hotosm_tha_roads_lines_shp\") %&gt;%\n  st_make_valid() %&gt;% st_set_crs(4326) %&gt;% st_transform(crs = st_crs(bmr_full))\n\nThe code below then finds the network within BMR by using st_intersection() to find the overlap between the full road network and the BMR boundary.\n\nbmr_network &lt;- st_intersection(network, bmr_full)\n\nCalling the object name allows us to inspect the contents.\n\nbmr_network\n\nSimple feature collection with 584672 features and 14 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 587921 ymin: 1484439 xmax: 712417 ymax: 1579041\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n             name               name_en        highway  surface smoothness\n1      ถนนฉลองกรุง    Chalong Krung Road      secondary    paved       &lt;NA&gt;\n2  ซอยฉลองกรุง 1/1 Soi Chalong Krung 1/1    residential     &lt;NA&gt;       &lt;NA&gt;\n3            &lt;NA&gt;                  &lt;NA&gt; secondary_link     &lt;NA&gt;       &lt;NA&gt;\n4            &lt;NA&gt;                  &lt;NA&gt;        service     &lt;NA&gt;       &lt;NA&gt;\n5      ถนนฉลองกรุง    Chalong Krung Road      secondary concrete       &lt;NA&gt;\n6            &lt;NA&gt;                  &lt;NA&gt;        service     &lt;NA&gt;       &lt;NA&gt;\n7     ถนนเอราวัณ 1         Erawan 1 Road       tertiary     &lt;NA&gt;       &lt;NA&gt;\n9            &lt;NA&gt;                  &lt;NA&gt;        service     &lt;NA&gt;       &lt;NA&gt;\n10           &lt;NA&gt;                  &lt;NA&gt;    residential     &lt;NA&gt;       &lt;NA&gt;\n11           &lt;NA&gt;                  &lt;NA&gt;        service     &lt;NA&gt;       &lt;NA&gt;\n   width lanes oneway bridge layer source        name_th     osm_id  osm_type\n1   &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;     ถนนฉลองกรุง 1125681229 ways_line\n2   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; ซอยฉลองกรุง 1/1  594401607 ways_line\n3   &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;           &lt;NA&gt;  472283206 ways_line\n4   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;           &lt;NA&gt;  594401608 ways_line\n5   &lt;NA&gt;     2    yes    yes     1   Bing     ถนนฉลองกรุง  116847248 ways_line\n6   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;           &lt;NA&gt;  317485095 ways_line\n7   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนเอราวัณ 1  378672881 ways_line\n9   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;           &lt;NA&gt;  909942692 ways_line\n10  &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;           &lt;NA&gt;  694824299 ways_line\n11  &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;           &lt;NA&gt;  909946323 ways_line\n                         geometry\n1  LINESTRING (693686.1 151979...\n2  LINESTRING (693358 1519300,...\n3  LINESTRING (692949.1 151886...\n4  LINESTRING (693256 1519184,...\n5  LINESTRING (692810.8 151863...\n6  LINESTRING (693877.2 152042...\n7  LINESTRING (677182.3 156542...\n9  LINESTRING (629009.2 151425...\n10 LINESTRING (629703.9 151362...\n11 LINESTRING (629379.9 151353...\n\n\nThe size of the object has now been reduced to 585K features from the original 2.8M. This still appears a very large number if we want to visualize the data, so we need to inspect if there are any opportunities to reduce the dataset by excluding any irrelevant records.\nThe data includes a column named highway which gives information on the the type or classification of the road.\n\nggplot(bmr_network, aes(x = reorder(highway, table(highway)[highway]))) +\n  geom_bar() +\n  coord_flip() +\n  ggtitle(\"Number of Roads by Highway type\") +\n  theme_minimal() +\n  geom_text(stat='count', aes(label=..count..), hjust=-0.3) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12),\n    axis.text.x = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(x = \"Number of Records\", y = \"Highway Type\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nThe resulting chart shows that roads with highway type of residential and service make up 522K of the 585K roads in the dataset. We refer to the OpenStreetMap wiki page to see the definition of the different types of highways in the Thailand map and see that these two highway types are access roads for residences or specific buildings. For our objective, we should be able to limit to roads where accidents (are expected to frequently) happen, and only to roads that should be accessible by vehicles. Going through the definition of the highway types, we see that the following 6 types could be out of scope for our study:\n\nresidential - road within a residential area that gives public access to one or multiple residences\nservice - minor road that gives access to buildings or places outside a residential area (e.g., to a religious site, an attraction, part of an estate)\nfootway - pathways designed for pedestrian access\ntrack - road whose only function is to provide access to surrounding land, and is most of the time unpaved\npath - multi-purpose path intended for non-motor vehicles\nsteps\n\nWe can then use the following code chunk which uses the filter() function to remove these classifications from the current network object. We call the object name in the succeeding code chunk to check the new dataset.\n\nbmr_network &lt;- bmr_network %&gt;% \n  filter(!(highway %in% c(\"residential\", \"service\", \"footway\", \"track\", \"path\", \"steps\")))\n\n\nbmr_network\n\nSimple feature collection with 34056 features and 14 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 590124.8 ymin: 1484506 xmax: 712235 ymax: 1579041\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n           name                    name_en        highway  surface smoothness\n1    ถนนฉลองกรุง         Chalong Krung Road      secondary    paved       &lt;NA&gt;\n2          &lt;NA&gt;                       &lt;NA&gt; secondary_link     &lt;NA&gt;       &lt;NA&gt;\n3    ถนนฉลองกรุง         Chalong Krung Road      secondary concrete       &lt;NA&gt;\n4   ถนนเอราวัณ 1              Erawan 1 Road       tertiary     &lt;NA&gt;       &lt;NA&gt;\n5     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n6     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n7     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n8     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n9  ถนนบรมราชชนนี Borommaratchachonnani Road          trunk  asphalt       &lt;NA&gt;\n10         &lt;NA&gt;                       &lt;NA&gt;   unclassified     &lt;NA&gt;       &lt;NA&gt;\n   width lanes oneway bridge layer source      name_th     osm_id  osm_type\n1   &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   ถนนฉลองกรุง 1125681229 ways_line\n2   &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  472283206 ways_line\n3   &lt;NA&gt;     2    yes    yes     1   Bing   ถนนฉลองกรุง  116847248 ways_line\n4   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  ถนนเอราวัณ 1  378672881 ways_line\n5   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา 1312138113 ways_line\n6   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา 1312138112 ways_line\n7   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา  155900618 ways_line\n8   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา  156365723 ways_line\n9   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; ถนนบรมราชชนนี  615741634 ways_line\n10  &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  106732198 ways_line\n                         geometry\n1  LINESTRING (693686.1 151979...\n2  LINESTRING (692949.1 151886...\n3  LINESTRING (692810.8 151863...\n4  LINESTRING (677182.3 156542...\n5  LINESTRING (676813.7 154284...\n6  LINESTRING (677134.2 154283...\n7  LINESTRING (675989.4 154300...\n8  LINESTRING (676815 1542831,...\n9  LINESTRING (632625.1 152356...\n10 LINESTRING (620655.3 152906...\n\n\nThe new road network object is now reduced to 34K records or roads which is a 94% reduction in the number of records. We will use some visual inspection to see if this reduction in records will affect our analysis. The two code chunks below plot the road network within the boundaries, while the second plots the three objects together. We use the tmap function to create these maps.\n\nBMR filtered road network onlyBMR filtered road network with road accident dataset\n\n\n\ntm_shape(bmr_full) +\n  tm_polygons(col = \"lightgrey\") +\n  tm_shape(bmr_network) +\n  tm_lines(col = \"black\", alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(bmr_full) +\n  tm_polygons(col = \"lightgrey\") +\n  tm_shape(bmr_network) +\n  tm_lines(col = \"darkblue\") +\n  tm_shape(bmracc) +\n  tm_dots(col = \"red\", alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\n\nFrom these two maps, we see that:\n\nwhile we have filtered 90% of the original records, the resulting map still appears dense, especially in some central areas; and,\nthe road accident locations appear to fall along the network\n\nBased on these, we will go ahead with this version of the network for our analysis.\nThe following code writes the resulting network into an rds file for more convenient loading in the future.\n\nwrite_rds(bmr_network, \"data/rds/bmr_network.rds\")"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.5-pre-analysis-transformations",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.5-pre-analysis-transformations",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.5 Pre-analysis transformations",
    "text": "B.5 Pre-analysis transformations\nIn this section, we perform some additional transformations to perform the required analyses.\nXX jitter xx\nxx creating seasonal mapping or other time based tagging xx"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "",
    "text": "Data for this exercise are from public sources and will be used to analyse the distribution of childcare centers in the Punggol planning area. Two datasets in ESRI shapefile format will be used:\n\nA line feature geospatial dataset which includes the road network of Punggol planning area\nA point feature geospatial dataset which includes the location of childcare centers in the Punggol planning area\n\n\n\n\nThis exercise will make use of five R packages: sf, spNetwork, tidyverse, and tmap.\n\nsf - for importing, managing and processing vector-based geospatial data\ntidyverse - collection of packages for performing data importation, wrangling and visualization\ntmap - for plotting cartographic quality maps\nsPNetwork - provides functions for performing SPPA methods like KDE and K-function on a network. The package can also be used to build spatial matrices to conduct traditional spatial analyses with spatial weights based on reticular distances\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)\n\nWe use the random seed 1234 to ensure reproducibility of results\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#data-sources",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#data-sources",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "",
    "text": "Data for this exercise are from public sources and will be used to analyse the distribution of childcare centers in the Punggol planning area. Two datasets in ESRI shapefile format will be used:\n\nA line feature geospatial dataset which includes the road network of Punggol planning area\nA point feature geospatial dataset which includes the location of childcare centers in the Punggol planning area"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#installing-and-launching-r-packages",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#installing-and-launching-r-packages",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "",
    "text": "This exercise will make use of five R packages: sf, spNetwork, tidyverse, and tmap.\n\nsf - for importing, managing and processing vector-based geospatial data\ntidyverse - collection of packages for performing data importation, wrangling and visualization\ntmap - for plotting cartographic quality maps\nsPNetwork - provides functions for performing SPPA methods like KDE and K-function on a network. The package can also be used to build spatial matrices to conduct traditional spatial analyses with spatial weights based on reticular distances\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)\n\nWe use the random seed 1234 to ensure reproducibility of results\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#visualization-of-the-sf-objects",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#visualization-of-the-sf-objects",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "Visualization of the sf objects",
    "text": "Visualization of the sf objects\nThe code below uses plot() in one map. The add=T argument in the second line allows the two plots to be added one over the other.\n\nplot(st_geometry(network))\nplot(childcare, add=T, col=\"red\", pch=10)\n\n\n\n\n\n\n\n\nThe following code chunk produces a similar map using tmap package.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(network) +\n  tm_lines() +\n  tm_shape(childcare) +\n  tm_dots(col = \"red\")\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#preparing-the-lixels-objects",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#preparing-the-lixels-objects",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "Preparing the lixels objects",
    "text": "Preparing the lixels objects\nA requirement for NKDE is that the lines objects needs to be cut into lixels. The code below uses lixelize_lines() on network, using a length of 700 and a minimum distance (mindist) of 350.\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 350)"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#generating-the-line-center-points",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#generating-the-line-center-points",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "Generating the line center points",
    "text": "Generating the line center points\nThe code below generates the center points for the lixels\n\nsamples &lt;- lines_center(lixels)\n\nxxx\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines() +\n  tm_shape(samples) +\n  tm_dots(size = 0.01)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#computing-nkde",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#computing-nkde",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "Computing NKDE",
    "text": "Computing NKDE\nThe code below computes for the NKDE of childcare centres around network\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nThe output of the code is a list of density or intensity values. We copy these values into the original lixel and lixel midpoint dataframes.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nNote that the previous values are based on metres and resulted in very low density values. We can change the density values to event per square km by using the code below\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000"
  },
  {
    "objectID": "In-class/In-class_Ex03/In-class_Ex03.html#computing-the-k-and-g-functions",
    "href": "In-class/In-class_Ex03/In-class_Ex03.html#computing-the-k-and-g-functions",
    "title": "Advanced SPPA Methods - NCKDE",
    "section": "Computing the K and G Functions",
    "text": "Computing the K and G Functions\nThe code block below computes for the K- and G-functions based on the data using kfunctions()\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 49, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\nThe output can be visualized by calling plotk for the K-function and plotg for the G-function\n\nkfun_childcare$plotk"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "The exercise uses the following data sources:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg in SHP and KML formats\nMaster Plan 2019 Subzone Boundary from data.gov.sg\nPre-school locations from data.gov.sg\nSingapore 2023 population from singstat.gov.sg\n\n\n\n\nThis exercise will make use of four R packages: sf, tidyverse, ggstatsplot and tmap.\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#data-sources",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#data-sources",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "The exercise uses the following data sources:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg in SHP and KML formats\nMaster Plan 2019 Subzone Boundary from data.gov.sg\nPre-school locations from data.gov.sg\nSingapore 2023 population from singstat.gov.sg"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#installing-and-launching-r-packages",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#installing-and-launching-r-packages",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "This exercise will make use of four R packages: sf, tidyverse, ggstatsplot and tmap.\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#importing-the-geospatial-data",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#importing-the-geospatial-data",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "Importing the Geospatial Data",
    "text": "Importing the Geospatial Data\nThe code chunk below loads the Masterplan subzone boundary shape file as a dataframe mpsz14_shp\n\nmpsz14_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe code chunk below loads the Masterplan subzone boundary KML file as a dataframe mpsz14_kml\n\nmpsz14_kml = st_read(\"data/geospatial/MasterPlan2014SubzoneBoundary.kml\")\n\nRunning the code shows that the data is likely corrupted as it is not being properly loaded into R. To illustrate loading the same data in KML format, we can create a clean KML file using st_write()\n\nst_write(mpsz14_shp,\n         \"data/geospatial/MP14SubzoneBoundary.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/geospatial/MP14SubzoneBoundary.kml' using driver `KML'\nWriting layer `MP14SubzoneBoundary' to data source \n  `data/geospatial/MP14SubzoneBoundary.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\nmpsz14_kml = st_read(\"data/geospatial/MP14SubzoneBoundary.kml\")\n\nReading layer `MP14SubzoneBoundary' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MP14SubzoneBoundary.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the 2019 Masterplan subzone boundary SHP file as a dataframe mpsz19_shp\n\nmpsz19_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe output shows that the data uses a geographic coordinate system instead of a projected coordinate system that we need for analysis. This needs to be translated before we can analyze this data with our other datasets. To do this, we can revise the code to:\n\nmpsz19_shp = st_read(dsn = \"data/geospatial\", \n                  layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the KML file and also shows we have it in geographic coordinate system.\n\nmpsz19_kml = st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the preschool location in KML format into a dataframe\n\npreschool_kml = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the preschool location in GeoJSON format into a dataframe\n\npreschool_geojson = st_read(\"data/geospatial/PreSchoolsLocation.geojson\") \n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe last two files are again in GCS (WGS84) rather than projected coordinate system (SVY21) We can reconfirm this with the next code chunk\n\nst_crs(preschool_kml)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nWe can use the following code to import the preschool location and project it into SVY21\n\npreschool &lt;- st_read(\"data/geospatial/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nst_crs(preschool)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe code chunks below load the Master Plan 2019 Subzone Boundary Data into R dataframes\n\nmpsz19_shp &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_kml &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below checks the CRS information of mpsz19_shp\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nIt appears mpsz19_shp does not have the correct EPSG code of 3414. The same is true for preschool. The code chunk below reloads the information and already applies the correct EPSG code\n\nmpsz19_shp &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\npreschool &lt;- st_read(\"data/geospatial/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\In-class\\In-class_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nThe code chunk below counts the number of preschools in each planning subzone\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\nThe code below then does the following in one line of code:\n\nDerives the area of each planning zone\nDrops the unit of measurement of the area\nCalculates the density of pre-schools at each planning zone\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#statistical-analysis",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#statistical-analysis",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nOnce we have computed the area, we can perform the appropriate analysis to see if there are any relationships.\nThe code below creates a plot of the preschool density and the preschool count using ggscatterstats() of ggstatsplot package\n\nmpsz19_shp$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\nmpsz19_shp$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) \nmpsz19_shp &lt;- as.data.frame(mpsz19_shp)\n\nggscatterstats(data = mpsz19_shp,\n               x = `PreSch Density`,\n               y = `PreSch Count`,\n               type = \"parametric\")\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#importing-and-wrangling-aspatial-data",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#importing-and-wrangling-aspatial-data",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "Importing and Wrangling Aspatial Data",
    "text": "Importing and Wrangling Aspatial Data\nWe load the 2023 population data into a dataframe called popdata and see that there are 101K rows and 7 columns.\n\npopdata = read_csv(\"data/aspatial/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe code chunk below prepares a dataframe showing the population by planning area and planning subzone\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\nWe then convert the dataframe where the age ranges are grouped into three groups (ECONOMY ACTIVE, AGED, YOUNG) and also introduce the DEPENDENCY column which is the ratio of YOUNG and AGED compared to ECONOMY ACTIVE\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "In-class/In-class_Ex01/In-class_Ex01.html#joining-aspatial-data-with-geospatial-data",
    "href": "In-class/In-class_Ex01/In-class_Ex01.html#joining-aspatial-data-with-geospatial-data",
    "title": "In-Class Exercise 1: Introduction to Geospatial Analytics",
    "section": "Joining Aspatial Data with Geospatial Data",
    "text": "Joining Aspatial Data with Geospatial Data\nthe code chunk below combines the population information with the geospatial data for the planning zone boundaries\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html",
    "title": "Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we learn how to compute spatial weights and spatially lagged in R using the spdep package.\nThis exercise is based on Chapter 8 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#data-sources",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#data-sources",
    "title": "Spatial Weights and Applications",
    "section": "Data Sources",
    "text": "Data Sources\nData for this exercise are based on the Hunan county coming from two files:\n\nHunan county boundary layer in ESRI shapefile format\nHunan local development indicators for 2012 stored in a csv file"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#installing-and-launching-r-packages",
    "title": "Spatial Weights and Applications",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of five R packages: sf, tidyverse, tmap, and spdep.\n\nsf - for importing, managing and processing vector-based geospatial data\ntidyverse - collection of packages for performing data importation, wrangling and visualization\ntmap - for plotting cartographic quality maps\nspdep - functions to create spatial weights\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#data-loading",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#data-loading",
    "title": "Spatial Weights and Applications",
    "section": "Data Loading",
    "text": "Data Loading\nThe code chunk below uses st_read() of the sf package to load the Hunan shapefile into an R object.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe following code chunk imports the second data source, a csv file, into an R object using read_csv() of the readr package.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can examine the contents of the two objects by calling them.\n\nhunan sf dataframehunan2012 dataframe\n\n\n\nhunan\n\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3 Shape_Leng Shape_Area    County\n1   Changde 21098   Anxiang      County   1.869074 0.10056190   Anxiang\n2   Changde 21100   Hanshou      County   2.360691 0.19978745   Hanshou\n3   Changde 21101    Jinshi County City   1.425620 0.05302413    Jinshi\n4   Changde 21102        Li      County   3.474325 0.18908121        Li\n5   Changde 21103     Linli      County   2.289506 0.11450357     Linli\n6   Changde 21104    Shimen      County   4.171918 0.37194707    Shimen\n7  Changsha 21109   Liuyang County City   4.060579 0.46016789   Liuyang\n8  Changsha 21110 Ningxiang      County   3.323754 0.26614198 Ningxiang\n9  Changsha 21111 Wangcheng      County   2.292093 0.13049161 Wangcheng\n10 Chenzhou 21112     Anren      County   2.240739 0.13343936     Anren\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#performing-relational-join",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#performing-relational-join",
    "title": "Spatial Weights and Applications",
    "section": "Performing relational join",
    "text": "Performing relational join\nThe code chunk below will be used to import columns from hunan2012 into hunan using left_join() of the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#computing-queen-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbours",
    "text": "Computing (QUEEN) contiguity based neighbours\nThe code chunk below computes for a Queen contiguity weight matrix and displays a summary.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe output shows that:\n\nThere are 88 units in the dataset.\nThe most connected unit has 11 neighbours (and only one unit has 11 neighbours)\nThere are two units with only one neighbour.\n\nThe resulting polygon object wm_q lists all neighboring polygons for each polygon. For example, the following code will show the neighbors of the first polygon:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nThis shows that there are 5 neighbors for the first polygon. The numbers denote the id of those neighbors as they are stored in hunan.\nWe can retrieve the names of those polygons or units using the code chunk below. The columns County and NAME_3 contain the same value so either may be used to return the names\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these countries using the code below (for polygon 1 and then for its five neighbours)\n\nhunan$GDPPC[1]\n\n[1] 23667\n\nhunan$GDPPC[wm_q[[1]]]\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe complete weight matrix can be displayed by using str(), i.e., str(wm_q)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#computing-rook-contiguity-based-neighbours",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#computing-rook-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "Computing (ROOK) contiguity based neighbours",
    "text": "Computing (ROOK) contiguity based neighbours\nThe code chunk below computes the Rook contiguity weight matrix by setting the queen argument to FALSE\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe report shows a few differences compared to the earlier QUEEN contiguity matrix. The most connected area has 10 instead of 11 neighbors, and there are differences in the details from the number of nonzero links to the average number of links."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#visualizing-contiguity-weights",
    "href": "Hands-on/Hands-On_Ex06/Hands-On_Ex06.html#visualizing-contiguity-weights",
    "title": "Spatial Weights and Applications",
    "section": "Visualizing contiguity weights",
    "text": "Visualizing contiguity weights\nIn this section, we introduce connectivity graphs which displays lines between neighboring points. As we are working with a polygon object at the moment, we would need to convert or define points to represent them first before attempting to build a connectivity graph. The most common method to do this is by choosing the centroid as the point for the polygon\n\nGetting longitude and latitude of polygon centroids\nThe process is slightly complicated as we cannot immediately simply run st_centroid() on the object.\nFirst, we need to get the coordinates of the polygons in separate dataframe by using a mapping function. The code chunk below create a dataframe for the centroids along the longitude by using st_centroid() on the geometry longitude using double bracket notation.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nFor the latitudes, we use a similar code with the only difference being the index referenced by the double bracket notation.\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWe can then use cbind() to combine the two objects into a single object for the centroid locations.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe can confirm that the points are formatted correctly by checking the first few records with head()\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\nPlotting Queen contiguity based neighbours map\nThe code below creates the connectivity graph based on the matrix in wm_q\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map\nThe code below creates the connectivity graph based on the matrix in wm_r\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nPlotting Queen and Rook contiguity based neighbours map\nThe code below creates the connectivity graph for both queen and rook based contiguity and show theem side by side\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, we continue learning about Spatial Point pattern analysis with the help of spatstat package. We continue looking at the dataset using the location of childcare centres in Singapore.\nThis exercise is based on Chapter 5 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#data-sources",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#data-sources",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Data Sources",
    "text": "Data Sources\nData for this exercise are from public sources and are the same as the previous hands-on exercise. This includes:\n\nLocation and attribute information of childcare centres in Singapore from data.gov.sg\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nNational boundary of Singapore provided in SLA and ESRI shapefile format"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#installing-and-launching-r-packages",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of five R packages: sf, tidyverse, spatstat, raster and tmap.\n\nsf - for importing, managing and processing vector-based geospatial data\ntidyverse - collection of packages for performing data importation, wrangling and visualization\ntmap - for plotting cartographic quality maps\nspatstat - offers a wide range of functions for point pattern analysis (PPA)\nraster - for reading, writing, manipulating and analysing models of gridded spatial data\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#importing-the-spatial-data",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#importing-the-spatial-data",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Importing the spatial data",
    "text": "Importing the spatial data\nThe code chunk below uses st_read() from the sf package to import the geospatial datasets.\n\nchildcare_sf &lt;- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %&gt;% st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex04\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#checking-and-converting-projection-systems",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#checking-and-converting-projection-systems",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Checking and converting projection systems",
    "text": "Checking and converting projection systems\nWe can use st_crs() to check what coordinate systems are used in each of the three sf dataframes.\nchildcare_sf is in SVY21 using EPSG code 3414 after our load and transform operation above. However, sg_sf and mpsz_sf reveals that they are not using the correct EPSG code.\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe use the code chunk below to update the EPSG code for the last two objects\n\nsg_sf = st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nmpsz_sf = st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#mapping-the-geospatial-datasets",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#mapping-the-geospatial-datasets",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Mapping the geospatial datasets",
    "text": "Mapping the geospatial datasets\nIt is always good practice to plot or display imported data to check that they have been loaded and transformed properly. The code chunk below creates a map using tmap with all three objects where they appear to be mapped properly.\n\ntm_shape(sg_sf)+\n    tm_fill(\"lightblue\") +\n    tm_borders(lwd = 0.1,  alpha = 1)+\n    tm_shape(mpsz_sf) +\n    tm_fill(\"grey\", alpha = 0.5) +\n    tm_borders(lwd = 0.1,  alpha = 1) +\n    tm_shape(childcare_sf) +\n    tm_dots(col = \"darkgreen\")"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-sf-dataframe-sp-spatial-class",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-sf-dataframe-sp-spatial-class",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Converting sf dataframe sp spatial class",
    "text": "Converting sf dataframe sp spatial class\nThe code chunk below converts the three dataframes using as_Spatial() from the sf package.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nWe can check the contents of the new dataframes by calling them. This confirms that they are in the spatial* class format.\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-the-spatial-class-to-generic-sp-format",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-the-spatial-class-to-generic-sp-format",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Converting the spatial class to generic sp format",
    "text": "Converting the spatial class to generic sp format\nspatstat requires that the data is in ppp object form. There is no direct way to do this from spatial* class. We need to convert spatial* class to a spatial object first.\nThe code chunk below transform two of the spatial* objects into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nCalling childcare_sp and sg_sp lets us check their properties.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Converting generic sp format into spatstat’s ppp format",
    "text": "Converting generic sp format into spatstat’s ppp format\nWe will then use as.ppp() from spatstat package to convert the (spatial) data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nWe see the difference of this format when we use plot() (from R Graphics) to produce a quick map of the data.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nWe can see summary information on the new ppp object using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#handling-duplicated-points",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#handling-duplicated-points",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Handling duplicated points",
    "text": "Handling duplicated points\nWe can check duplication in a ppp object using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of coincident points, we can use the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe can wrap this in sum() to count the number of locations with more than one event.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThe outputs show that there are no duplication in childcare_ppp"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#creating-owin-object",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#creating-owin-object",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Creating owin object",
    "text": "Creating owin object\nWhen analysing spatial point patterns, it is best to confine the analysis within a geographical area. In spatstat, the object that represents the bounded region is called an owin.\nThe code chunk below creates an owin based on the sg SpatialPolygon object.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe owin object can be displayed graphically using plot() and summarized using summary()\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#combining-point-events-object-and-owin-object",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Combining point events object and owin object",
    "text": "Combining point events object and owin object\nIn this last step, we extract childcare events (locations) that are within Singapore, as depicted by the owin, using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output is a combination of the point feature and the polygon feature into a single ppp object:\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nRunning plot() on this shows both the owin and the preschool locations in a single map.\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#extracting-study-areas",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#extracting-study-areas",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Extracting study areas",
    "text": "Extracting study areas\nThe code chunk below extracts the target planning areas from mpsz_sf\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nThe code chunks below plot the different target planning areas using tmap_arrange().\n\npunggol &lt;- tm_shape(pg) + \n  tm_polygons() + tm_layout(title = \"Punggol\")\n\ncck &lt;- tm_shape(ck) + \n  tm_polygons() + tm_layout(title = \"Chua Chu Kang\")\n\ntampines &lt;- tm_shape(tm) + \n  tm_polygons() + tm_layout(title = \"Tampines\")\n\njwest &lt;- tm_shape(jw) + \n  tm_polygons() + tm_layout(title = \"Jurong West\")\n\ntmap_arrange(punggol, tampines, cck, jwest, asp=2, ncol=2, nrow = 2)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-target-areas-into-owin-objects",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#converting-target-areas-into-owin-objects",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Converting target areas into owin objects",
    "text": "Converting target areas into owin objects\nThe code chunk below converts the four objeects into owin which is a requirement for analysing with spatstat\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#combining-childcare-points-and-the-study-area",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#combining-childcare-points-and-the-study-area",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Combining childcare points and the study area",
    "text": "Combining childcare points and the study area\nThe code chunk below extracts the childcare points/events that are within each of the target areas\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nWe use rescale.ppp() in the next code chunk to transform the unit of measure from meter to kilometer\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot the four target areas and the locations of their childcare centres\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-g-function",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Analysing spatial point process using G function",
    "text": "Analysing spatial point process using G function\nThe G function measures the distribution of distances from an arbitrary event to the nearest event. We will compute the G function using Gest() of the spatstat package. We will also perform monte carlo simulation using the envelope() function of the same package.\n\nG-Function Estimation for Choa Chu Kang Planning Area\n\nComputing the G function estimation\nThe code chunk below computes the G-function for the planning area using Gest()\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Choa Chu Kang are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Choa Chu Kang are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the G-function values using envelope()\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nWe then plot the results using the code chunk below\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nG Function Estimation for Tampines Planning Area\n\nComputing the G function estimation\nThe code chunk below computes the G-function for the planning area using Gest()\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Tampines are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Tampines are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the G-function values using envelope()\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-f-function",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Analysing Spatial Point Process using F-Function",
    "text": "Analysing Spatial Point Process using F-Function\nThe F-Function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will compute the F-function using Fest() of the spatstat package. We will again use monte carlo simulation using envelope()\n\nF-Function Estimation for Choa Chu Kang Planning Area\n\nComputing the F-function estimation\nThe code chunk below computes the F-function for the planning area using Fest()\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Choa Chu Kang are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Choa Chu Kang are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the F-function values using envelope()\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nF-Function Estimation for Tampines Planning Area\n\nComputing the F-function estimation\nThe code chunk below computes the F-function for the planning area using Fest()\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Tampines are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Tampines are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the F-function values using envelope()\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-k-function",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Analysing Spatial Point Process using K-Function",
    "text": "Analysing Spatial Point Process using K-Function\nThe K-function measures the number of events found up to a given distance of any particular event. In this section, we will use Kest() of the spatstat package to estimate the K-function. We will again perform monte carlo simulations using envelope()\n\nK-Function Estimation for Choa Chu Kang Planning Area\nThe code chunk below computes the K-function for the planning area using Kest()\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Choa Chu Kang are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Choa Chu Kang are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the K-function values using envelope()\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\nK-Function Estimation for Tampines Planning Area\nThe code chunk below computes the K-function for the planning area using Kest()\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Tampines are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Tampines are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the K-function values using envelope()\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on/Hands-On_Ex04/Hands-On_Ex04.html#analysing-spatial-point-process-using-l-function",
    "title": "Second Order Spatial Point Pattern Analysis Methods",
    "section": "Analysing Spatial Point Process using L-Function",
    "text": "Analysing Spatial Point Process using L-Function\nIn this section, we will use Lest() of the spatstat package to estimate the L-function. We will again perform monte carlo simulations using envelope()\n\nL-Function Estimation for Choa Chu Kang Planning Area\nThe code chunk below computes the L-function for the planning area using Lest()\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Choa Chu Kang are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Choa Chu Kang are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the L-function values using envelope()\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\nL-Function Estimation for Tampines Planning Area\nThe code chunk below computes the L-function for the planning area using Lest()\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\nTo confirm the observed spatial pattern, we conduct hypothesis testing. The test hypotheses for these are:\n\n\\(H_0\\) - The locations of childcare service centres in Tampines are randomly distributed\n\\(H_1\\) - The locations of childcare service centres in Tampines are not randomly distributed\n\nFor our testing, we will use a p-value smaller than α = 0.001 to reject the null hypothesis.\nThe code chunk below produces monte carlo simulation for the L-function values using envelope()\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html",
    "title": "Choropleth Mapping with R",
    "section": "",
    "text": "For this hands-on exercise, we learned how to plot choropleth maps by using an R package called tmap\nThis exercise is based on Chapter 2 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-sources",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-sources",
    "title": "Choropleth Mapping with R",
    "section": "Data Sources",
    "text": "Data Sources\nThe exercise will use the following publicly available datasets:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 from singstat.gov\n\nThe first one is geospatial data and was also used in the previous hands-on exercise. The second source is for aspatial data but the PA and SZ fields in it allows geocoding into the shapefile."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#installing-and-launching-r-packages",
    "title": "Choropleth Mapping with R",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of three R packages: sf, tidyverse and tmap. We have already introduced the first two in the last exercise: tidyverse is a family of R packages used for data wrangling and visualization, while sf is used for importing, managing and processing geospatial data. Tidyverse is made up of multiple packages which include tidyr and dplyr which will be the specific packages where the functions we use will come from.\nTmap stands for thematic map and will enable us to create the functional choropleth maps that go beyond the capabilities of plot()\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap)\ntmap_options(show.messages = FALSE)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-geospatial-data-into-r",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-geospatial-data-into-r",
    "title": "Choropleth Mapping with R",
    "section": "Importing Geospatial Data into R",
    "text": "Importing Geospatial Data into R\nWe first import MP14_SUBZONE_WEB_PL using st_read() function by providing the path and the layer name as parameters.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can examine the contents by calling the dataframe like in the code chunk below. This function call only shows the first 10 features or rows of the dataframe.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-attribute-data-into-r",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#importing-attribute-data-into-r",
    "title": "Choropleth Mapping with R",
    "section": "Importing Attribute Data into R",
    "text": "Importing Attribute Data into R\nOur remaining data is in a csv file which we will load into a dataframe called popdata using read_csv() which comes from the readr package that is included in tidyverse.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can quickly examine the data by calling the dataframe name. This shows that popdata consists of 738K records or rows with 7 attributes or columns.\n\npopdata\n\n# A tibble: 738,492 × 7\n   PA         SZ                     AG     Sex     FA              Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &lt;= 60             0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;60 to 80        10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;80 to 100       30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;100 to 120      80  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   &gt;120             20  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Not Available     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &lt;= 60             0  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;60 to 80        10  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;80 to 100       40  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females &gt;100 to 120      90  2011\n# ℹ 738,482 more rows\n\n\nWe will use the 2020 information from this to build a new data table popdata2020 which includes the following variables:\n\nPA and SZ give information on the location (planning area and township)\nYOUNG is the population for those aged 0 to 24\nECONOMY ACTIVE is the population for those aged 25 to 64\nAGED is the population for those aged 65 and above\nTOTAL is the total population across all age groups\nDEPENDENCY is the ratio between young and aged against the economy active group"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-wrangling",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-wrangling",
    "title": "Choropleth Mapping with R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nTo generate the required table from popdata, we will use pivot_wider() of tidyr package, mutate(), filter(), group_by() and select() of dplyr package. All of these are included in tidyverse.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nWe can check that the transformation has been executed properly by displaying the new dataframe.\n\npopdata2020\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Cen…  1440             2640   770  4850      0.837\n 2 Ang Mo Kio Cheng San             6660            15380  6080 28120      0.828\n 3 Ang Mo Kio Chong Boon            6150            13970  6450 26570      0.902\n 4 Ang Mo Kio Kebun Bahru           5500            12040  5080 22620      0.879\n 5 Ang Mo Kio Sembawang Hills       2130             3390  1270  6790      1.00 \n 6 Ang Mo Kio Shangri-La            3970             8430  3540 15940      0.891\n 7 Ang Mo Kio Tagore                2220             4160  1520  7900      0.899\n 8 Ang Mo Kio Townsville            4720            11430  5050 21200      0.855\n 9 Ang Mo Kio Yio Chu Kang             0                0     0     0    NaN    \n10 Ang Mo Kio Yio Chu Kang East     1190             2230   740  4160      0.865\n# ℹ 322 more rows"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#joining-the-attribute-and-geospatial-data",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#joining-the-attribute-and-geospatial-data",
    "title": "Choropleth Mapping with R",
    "section": "Joining the attribute and geospatial data",
    "text": "Joining the attribute and geospatial data\nTo use this attribute data for our analysis, we need to join it with the geospatial data. The first step will be to convert the PA and SZ values to uppercase to make sure that they follow the same convention as the geospatial data. We use the mutate_at() function to apply this transformation.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThe next step is to use left_join() from dplyr to merge the two tables using SZ.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nAs the left side is an sf dataframe, the resulting object is also an sf dataframe and we write this into a file to store for future use without rerunning all the transformations so far.\n\nwrite_rds(mpsz_pop2020, \"data/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#plotting-a-choropleth-map-quickly-using-qtm",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#plotting-a-choropleth-map-quickly-using-qtm",
    "title": "Choropleth Mapping with R",
    "section": "Plotting a choropleth map quickly using qtm()",
    "text": "Plotting a choropleth map quickly using qtm()\nqtm() is a convenient way to produce a thematic or choropleth map. It provides a good default or initial visualization.\nThe code chunk below draws a standard choropleth map using the values from DEPENDENCY as the fill.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode(\"plot\") produces a static plot. To produce an interactive plot, tmap_mode(\"view\") should be used instead.\nqtm() takes the sf dataframe as its first argument. The fill argument defines which attribute to map."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Choropleth Mapping with R",
    "section": "Creating a choropleth map by using tmap’s elements",
    "text": "Creating a choropleth map by using tmap’s elements\nWhile convenient, the downside of qtm() is that it makes controlling the aesthetics of individual layers harder to control. Using tmap’s drawing elements allows more customization, and allows the production of higher quality maps.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nWe go through the different elements plotted and the respective functions below.\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elements.\nIn the code chunk below, tm_shape() is used to define the input data and then tm_polygons() draws the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nThe code chunk below generates a choropleth map of the dependency ratio by planning subzone by passing DEPENDENCY to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nA few points on tm_polygons():\n\nThe default binning used is called “pretty”. We will go more into data classification methods later\nThe default color scheme is YlOrRd (Yellow Orange Red) of ColorBrewer. We will also go more into color schemes later\nBy default, missing values are shaded grey\n\n\n\nDrawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is actually a wrapper of two other functions: tm_fill() and tm_border().\ntm_fill() shades the polygons using the default color scheme. The code chunk below draws the choropleth map with just this element.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_borders() adds the borders of the shapefile onto the map. We add this element to the previous code to produce a similar plot to the one generated with tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\ntm_borders() has the following (optional) arguments:\n\nalpha defines the transparency and takes a value of 0 (totally transparent) to 1 (totally opaque)\ncol defines the border colour\nlwd defines the border line width (default 1)\nlty defines the border line type (default solid)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-classification-methods-on-tmap",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#data-classification-methods-on-tmap",
    "title": "Choropleth Mapping with R",
    "section": "Data Classification Methods on tmap",
    "text": "Data Classification Methods on tmap\nData classification refers to grouping (a large number of) observations into data ranges or classes. tmap provides ten data classification methods which include: fixed, sd, equal, pretty, quantile, kmeans, hclust, bclust, fisher, and jenks\nThe data classification method can be defined by using the style argument in tm_fill() or tm_polygons()\n\nPlotting choropleth maps with built-in classification methods\nThe code below produces a plot using quantile data classification with 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code below produces a plot using equal data classification with 5 classes. Note that the previous chart produces evenly distributed classes, while this new chart has almost all but one zone in the first class.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code below produces a plot using jenks data classification. By changing the style argument, the other data classification methods can be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nPlotting Choropleth Maps with custom break\nThe builtin styles compute the class breaks or boundaries internally. To override this, the breakpoints can be set explicitly using the breaks argument of tm_fill()\nThe breaks defined will include the minimum and maximum. Therefore, to define n classes, n+1 breakpoints should be defined in the breaks argument.\nWe first run some descriptive statistics on DEPENDENCY before we define the breakpoints\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.7113  0.7926  0.8561  0.8786 19.0000      92 \n\n\nBased on the distribution, say we define the breakpoints for five classes to be 0.6, 0.7, 0.8 and 0.9 to split. We need to include a minimum, 0, and a maximum, 20, for the breaks argument.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 20)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#colour-schemes",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#colour-schemes",
    "title": "Choropleth Mapping with R",
    "section": "Colour Schemes",
    "text": "Colour Schemes\ntmap supports user-defined colour maps, and pre-defined colour maps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour map, we assign a value to the palette argument of tm_fill() as shown in the code below\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe choropleth map is shaded in blue where a darker shade corresponds to a higher value of DEPENDENCY. To reverse this behavior, we can add a “-” prefix to the passed value.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#map-layouts",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#map-layouts",
    "title": "Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\nMap layout refers to the combination of all map elements into a cohesive map. Aside from the objects, the other elements include the title, the scale bar, a compass, margins and aspect ratios.\n\nMap Legend\nSeveral options are provided to adjust the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMap Style\nA wide variety of layout settings can be changed by calling tmap_style()\nThe codeblock below shows the map using the classic style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\ntmap provides options to add other elements like a compass, scale, and grid lines. In the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add these elements.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nNote that the above map still uses the classic style. To revert to the default style, use the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#drawing-small-multiple-choropleth-maps",
    "title": "Choropleth Mapping with R",
    "section": "Drawing Small Multiple Choropleth Maps",
    "text": "Drawing Small Multiple Choropleth Maps\nSmall multiple maps or facet maps are composed of multiple maps arranged side-by-side. (in a grid, stacked vertically, lined up) Small multiple maps allow visualization of how spatial relationships change with respect to one variable. (e.g., time)\nThere are three ways to define small multiples in tmap:\n\nby assigning multiple values to at least one aesthetic argument,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange()\n\n\nAssigning multiple values to at least one of the aesthetic arguments\nIn the code below, small multiple maps are created by passing a list of (numeric) columns as the col argument of tm_fill() Each map depicts a different column or attribute.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn the next code, two parameters are passed to palette argument to result to different colour maps for the each small multiple.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nIn the code below, a small multiple of each region is created by using tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nBy creating multiple stand-alone maps and using tmap_arrange()\nIn the following code, two maps are defined individually and then displayed side by side using tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#mapping-spatial-objects-meeting-selection-criterion",
    "href": "Hands-on/Hands-On_Ex02/Hands-On_Ex02.html#mapping-spatial-objects-meeting-selection-criterion",
    "title": "Choropleth Mapping with R",
    "section": "Mapping Spatial Objects Meeting Selection Criterion",
    "text": "Mapping Spatial Objects Meeting Selection Criterion\nInstead of using small multiples to look at a particular subset of the data, you can also use a selection criteria or a mask to only map objects meeting a particular condition. The code below produces a map for only the Central Region.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there! I’m Derek (Federico Jose Rodriguez) and I built this website as I started taking my Geospatial Analytics and Applications course in the MITB Program of Singapore Management University in 2024."
  },
  {
    "objectID": "about.html#about-me-and-this-site",
    "href": "about.html#about-me-and-this-site",
    "title": "About",
    "section": "",
    "text": "Hi there! I’m Derek (Federico Jose Rodriguez) and I built this website as I started taking my Geospatial Analytics and Applications course in the MITB Program of Singapore Management University in 2024."
  },
  {
    "objectID": "about.html#quarto-websites",
    "href": "about.html#quarto-websites",
    "title": "About",
    "section": "Quarto Websites",
    "text": "Quarto Websites\nThis is a Quarto website.\nTo learn more about Quarto websites and start creating your own, please visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Geospatial Data Wrangling with R",
    "section": "",
    "text": "For this hands-on exercise, we performed basic data wrangling tasks using the sf package in R.\nThis exercise is based on Chapter 1 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#data-sources",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#data-sources",
    "title": "Geospatial Data Wrangling with R",
    "section": "Data Sources",
    "text": "Data Sources\nThe exercise will use the following publicly available datasets:\n\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nPre-Schools location from data.gov.sg\nCycling Path from LTA DataMall\nSingapore AirBNB listing data from Inside AirBNB\n\nThe files from the first three are loaded into a folder named geospatial, while the last one (AirBNB listings) is loaded into a folder named aspatial."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "title": "Geospatial Data Wrangling with R",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of two R packages: sf and tidyverse. Tidyverse is a family of R packages used for data wrangling and visualization. Sf is used for importing, managing and processing geospatial data.\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polygon-feature-data-in-shapefile-format",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing polygon feature data in shapefile format",
    "text": "Importing polygon feature data in shapefile format\nMP14_SUBZONE_WEB_PL is a polygon feature layer in ESRI shapefile format from the first data source. (Master Plan 2014 Subzone Boundary from data.gov.sg) This will get loaded into R as a polygon feature data frame.\nThe st_read() function call for ESRI shapefiles requires two arguments: dsn which defines the path, and layer which defines the shapefile name. The path only requires a folder and therefore does not require a file (with an extension) to be named. We load this data into a dataframe mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message confirms that the load is successful and that the objects are multipolygon features. It also gives information on the number of features (323), fields (15) and the coordinate system. (SVY21) The bounding box value defines the extent of the data."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polyline-feature-data-in-shapefile-format",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-polyline-feature-data-in-shapefile-format",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing polyline feature data in shapefile format",
    "text": "Importing polyline feature data in shapefile format\nCyclingPath is a line feature layer in ESRI shapefile format from the third data source. (Cycling Path from LTA) This will get loaded into R as a line feature data frame.\nA similar function call is used to load the data into R as a dataframe cyclingpath.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message confirms the type (Multistring), the number of features (3138) and fields (2) among other information."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-gis-data-in-kml-format",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-gis-data-in-kml-format",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing GIS data in kml format",
    "text": "Importing GIS data in kml format\nPreSchoolsLocation is a point feature layer in kml format from the second data source. (Preschools Location from data.gov.sg)\nThe st_read() function call for KML files requires one parameter, which is the complete path, including the kml filename. We load this data into a dataframe preschool.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message confirms the type (Point), the number of features (2290) and fields (2) among other information."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Geospatial Data Wrangling with R",
    "section": "Working with st_geometry()",
    "text": "Working with st_geometry()\nThe geometry column in the sf dataframe is a list of class sfc which contains the geometries. The contents of the column can be retrieved by:\n\ncalling the column using mpsz$geometry , mpsz$geom , or mpsz[[1]]\nusing the function st_geometry()\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Geospatial Data Wrangling with R",
    "section": "Working with glimpse()",
    "text": "Working with glimpse()\nThe glimpse() function from dplyr reveals the data type of each field and gives the first few observations.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Geospatial Data Wrangling with R",
    "section": "Working with head()",
    "text": "Working with head()\nThe Base R head() function reveals the first elements of the dataframe. The number of elements can be set by specifying an n argument. It also displays information for an sf dataframe like the geometry type, bounding box and projection system.\n\nhead(mpsz, n = 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-featured-data-frame",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-featured-data-frame",
    "title": "Geospatial Data Wrangling with R",
    "section": "Assigning EPSG code to a simple featured data frame",
    "text": "Assigning EPSG code to a simple featured data frame\nA common issue that can happen during importation of the data is that the coordinate system is missing or wrongly assigned during the process.\nThe st_crs() function can be used to display information on the coordinate system of an sf dataframe.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWhile mpsz appears to be projected in svy21 as expected, the output shows that it using EPSG code 9001 instead of 3414, which is the correct one for svy21. We can use the st_set_crs() function of sf to assign the correct EPSG code to mpsz. (as a new dataframe mpsz3414)\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nRunning st_crs() on mpsz3414 confirms that the new dataframe has the correct EPSG code assigned.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Geospatial Data Wrangling with R",
    "section": "Transforming the projection of preschool from wgs84 to svy21",
    "text": "Transforming the projection of preschool from wgs84 to svy21\nGeographic coordinate systems are not appropriate for geospatial analysis if the analysis requires distance or area measurements. Because of this, transforming data from geographic to projected coordinate systems is a common task.\nThe code block and output below shows that preschool is in the wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nSince reprojection is required, st_transform() from the sf package will be used. (st_set_crs() will not do the job) The following code chunk performs the reprojection into a new dataframe preschool3414.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nChecking the contents confirms that preschool3414 is now using the svy21 projected coordinate system.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Geospatial Data Wrangling with R",
    "section": "Importing the aspatial data",
    "text": "Importing the aspatial data\nThe appropriate function from the readr package should be used depending on the file format. For csv files, the read_csv() function loads our file into a tibble dataframe named listings\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe list() function from Base R displays the contents of the dataframe and also shows that there are 3540 rows and 75 columns.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nScanning through the columns reveals that there are columns named longitude and latitude which appear to be in decimal degree format. We will assume that these are recorded based on the wgs84 geographic coordinate system."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-from-an-aspatial-data-frame",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-from-an-aspatial-data-frame",
    "title": "Geospatial Data Wrangling with R",
    "section": "Creating a simple feature from an aspatial data frame",
    "text": "Creating a simple feature from an aspatial data frame\nWe use the code chunk below to create an sf dataframe listings_sf from the aspatial data in listings.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe used the following arguments in the above function call:\n\ncoords requires the column names of the x-coordinates followed by the y-coordinates\ncrs indicates the epsg format used in the data. EPSG 4326 corresponds to the wgs84 geographic coordinate system\n%&gt;% is used to nest st_transform() and transform the newly created sf dataframe into the svy21 coordinate system (EPSG 3414)\n\nWe can then use glimpse() on the new dataframe to examine the contents.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nThe output shows that a new column geometry has been introduced in the data, while the coordinate columns longitude and latitude have been dropped."
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\nSCENARIO\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nSOLUTION\nFirst, use st_buffer() to compute a 5m buffer around the cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nSecond, calculate the areas of the buffers with st_area().\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLast, summing the values of the new column using sum() will give the total land required.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nDone! 2.2 million square meters are required"
  },
  {
    "objectID": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Geospatial Data Wrangling with R",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\nSCENARIO 1\nA group wants to fund out the number of pre-schools in each planning subzone\nSOLUTION 1\nFirst, use st_intersects to identify preschools located in each planning subzone. (stored as a list) Then use lengths() from Base R to calculate the number of preschools in each planning subzone. This is stored in a new column PreSch Count\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThe new column can be summarized using summary() as shown. The output shows that the median number of preschools ranges from 0 to 72 and the median is 4.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nThe planning subzones with the most number of preschools can be displayed using the top_n() function of the dplyr package. This shows that Tampines East has the maximum number of 72 preschools.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nSCENARIO 2\nThe group also wants to understand the density of preschools. Larger subzones are expected to have more preschools so density might be a more appropriate measure to compare\nSOLUTION 2\nWe again use st_area to compute areas. This time we do this to compute for each subzone’s.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, the mutate() function from the dplyr package is used to compute the density\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nThe top_n() function can be used to fetch the subzone with the highest density, which is Cecil.\n\ntop_n(mpsz3414, 1, `PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            Area   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "",
    "text": "For this hands-on exercise, we start learning about Spatial Point pattern analysis, starting with First Order effects. (based on an underlying property or location)\nWe will be using the functions of the spatstat package, and applying it to an analysis on the location of childcare centres in Singapore.\nThis exercise is based on Chapter 4 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#data-sources",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#data-sources",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Data Sources",
    "text": "Data Sources\nData for this exercise are from public sources and include:\n\nLocation and attribute information of childcare centres in Singapore from data.gov.sg\nMaster Plan 2014 Subzone Boundary from data.gov.sg\nNational boundary of Singapore provided in SLA and ESRI shapefile format"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#installing-and-launching-r-packages",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of five R packages: sf, tidyverse, spatstat, raster, maptools and tmap. Among these, the new ones we are using are:\n\nspatstat - offers a wide range of functions for point pattern analysis (PPA)\nraster - used to read, write, manipulate and analyse models of gridded spatial data\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, spatstat, raster)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#importing-the-geospatial-data",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#importing-the-geospatial-data",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Importing the Geospatial Data",
    "text": "Importing the Geospatial Data\nWe use the st_read() function of the sf package to load the different geospatial datasets into R.\nThe code below loads the preschool location geoJSON file into the dataframe childcare_sf and projects it into SVY21.\n\nchildcare_sf &lt;- st_read(\"data/geospatial/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex03\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe code chunk below loads the Singapore National boundary shapefile into the dataframe sg_sf.\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThe code chunk below loads the Master Plan 2014 subzone boundary shapefile into another dataframe called mpsz_sf\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\drkrodriguez\\ISSS626-GAA\\Hands-on\\Hands-On_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can use st_crs() to check what coordinate systems are used in each of the three sf dataframes.\nchildcare_sf is in SVY21 using EPSG code 3414 after our load and transform operation above.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWhile sg_sf and mpsz_sf appeared to be in SVY21, running st_crs() reveals that they are not using the correct EPSG code.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nUsing st_set_crs() we can convert these and correct the crs information.\n\nsg_sf = st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nmpsz_sf = st_set_crs(mpsz_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nRerunning st_crs() shows that the correct EPSG code is now reflected.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#mapping-the-geospatial-data-sets",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Mapping the Geospatial Data Sets",
    "text": "Mapping the Geospatial Data Sets\nWith all three datasets in the same coordinate system, we can draw them in a single map as different layers using tm_shape() as in the following code chunk. See how the planning subzones extend beyond the defined coastal borders.\n\ntm_shape(sg_sf)+\n    tm_fill(\"lightblue\") +\n    tm_borders(lwd = 0.1,  alpha = 1)+\n    tm_shape(mpsz_sf) +\n    tm_fill(\"grey\", alpha = 0.5) +\n    tm_borders(lwd = 0.1,  alpha = 1) +\n    tm_shape(childcare_sf) +\n    tm_dots(col = \"darkgreen\")\n\n\n\n\n\n\n\n\nThe previous map shows the importance of using the same reference system across three different data sets for mapping and for analysis.\nAlternatively, we can prepare a pin map using the code below which switches to interactive mode using tmap_mode()\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\nInteractive maps allow the user to navigate and zoom in and out of the map freely. Features can also be queried by clicking on them. The background map layer is defaulted to ESRI.WorldGrayCanvas. There are two other available background map layers (ESRI.WorldToolMap and OpenStreetMap)\nIt is important to switch back to static mode (using the code below) when interactive maps are not required. This is as each interactive map uses a connection. The use of of interactive maps should be limited when publishing.\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#converting-sf-dataframe-sp-spatial-class",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#converting-sf-dataframe-sp-spatial-class",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Converting sf dataframe sp spatial class",
    "text": "Converting sf dataframe sp spatial class\nThe code chunk below converts the three dataframes using as_Spatial() from the sf package.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nWe can check the contents of the new dataframes by calling them. This confirms that they are in the spatial* class format.\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#converting-the-spatial-class-to-generic-sp-format",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#converting-the-spatial-class-to-generic-sp-format",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Converting the spatial class to generic sp format",
    "text": "Converting the spatial class to generic sp format\nspatstat requires that the data is in ppp object form. There is no direct way to do this from spatial* class. We need to convert spatial* class to a spatial object first.\nThe code chunk below transform two of the spatial* objects into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nCalling childcare_sp and sg_sp lets us check their properties.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#converting-generic-sp-format-into-spatstats-ppp-format",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Converting generic sp format into spatstat’s ppp format",
    "text": "Converting generic sp format into spatstat’s ppp format\nWe will then use as.ppp() from spatstat package to convert the (spatial) data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nWe see the difference of this format when we use plot() (from R Graphics) to produce a quick map of the data.\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nWe can see summary information on the new ppp object using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#handling-duplicated-points",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#handling-duplicated-points",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Handling duplicated points",
    "text": "Handling duplicated points\nWe can check duplication in a ppp object using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nTo count the number of coincident points, we can use the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe can wrap this in sum() to count the number of locations with more than one event.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThe outputs show that there are no duplication in childcare_ppp\nIf there are any duplicates, there are three possible approaches to handle them:\n\nDelete the duplicates. The downside of this is that some (useful) information will be lost\nJittering. Adding a small perturbation to the duplicate points so they do not occupy the exact same space\nMake each point unique, then attach the duplicates of the points as marks or attributes to the point\n\nThe code chunk below shows how jittering can be applied using rjitter()\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#creating-owin-object",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#creating-owin-object",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Creating owin object",
    "text": "Creating owin object\nWhen analysing spatial point patterns, it is best to confine the analysis within a geographical area. In spatstat, the object that represents the bounded region is called an owin.\nThe code chunk below creates an owin based on the sg SpatialPolygon object.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe owin object can be displayed graphically using plot() and summarized using summary()\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#combining-point-events-object-and-owin-object",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Combining point events object and owin object",
    "text": "Combining point events object and owin object\nIn this last step, we extract childcare events (locations) that are within Singapore, as depicted by the owin, using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output is a combination of the point feature and the polygon feature into a single ppp object:\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nRunning plot() on this shows both the owin and the preschool locations in a single map.\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#kernel-density-estimation-kde",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#kernel-density-estimation-kde",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Kernel Density Estimation (KDE)",
    "text": "Kernel Density Estimation (KDE)\n\nComputing KDE using automatic bandwidth selection method\nThe following code chunk computes the KDE for childcare services using density() from spatstat with the following parameters:\n\nbw.diggle() for automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl()\ngaussian as the smoothing kernel. This is already the default. Other smoothing methods that can be used are epanechnikov, quartic and disc\nThe intensity estimate is corrected for edge effect bias by using the method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nRunning this new object into plot() will display the derived KDE for the childcare events/locations\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe values stand for the density and currently range from 0 to 0.000035. These numbers are small and hard to visualize, but is a result of the unit of measurements used in the reference system, which is svy21. As svy21 uses meter as the unit of measure, the figures stand for number of points per square meter.\nWe can also retrieve the bandwidth used to compute the kde layer using the code chunk below\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\nRescaling KDE values\nThe code chunk below uses rescale.ppp() to convert the unit of measure from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nWe can then recompute the KDE and plot the new map with the rescaled data. The map will be the same but the KDE values will now represent the number of points per square kilometer\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\nWorking with different automatic bandwidth methods\nThere are three other spatstat functions that can be used to determine bandwidth: bw.CvL(), bw.scott(), and bw.ppl()\nWe can observe the different computed values by using the code chunks below:\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et al (2016) suggested the use of the bw.ppl() because in their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. They also insist that if the purpose of one’s study is to detect a single tight cluster in the midst of random noise then bw.diggle() seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle() and bw.ppl().\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\nWorking with different kernel methods\nThe default kernel method used is gaussian, but, as mentioned, there are three other options.\nThe code chunk below can be used to compare the KDE of the four different methods based on the output of plot()\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#fixed-and-adaptive-kde",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nComputing the KDE by using a fixed bandwidth\nThe code chunk below computes a KDE layer with a bandwidth of 600 meters. This is done by setting a sigma value of 0.6 as the unit of measurement is kilometer. (600m = 0.6km)\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km,\n                               sigma=0.6,\n                               edge=TRUE,\n                               kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\nComputing KDE by using an adaptive bandwidth\nFixed bandwidth will be sensitive to highly skewed distribution over geographic units– for example, in rural vs urban areas. One way to overcome this problem is by using adaptive bandwidths.\nThe code chunk below uses adaptive.density() to derive adaptive KDE.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can use the code chunk below to compare the outputs of using fixed and adaptive bandwidths\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\nConverting KDE output into grid object\nWe can convert the KDE output into a grid object using the code below\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nConverting gridded output into raster\nWe then convert the gridded KDE object into a RasterLayer object using raster() of the raster package\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nWe can take a look at the properties of thee new raster object by calling it as below. Note that the CRS property of this object is NA\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\nAssigning projection systems\nThe code chunk below will add CRS information into kde_childcare_SG_bw_raster raster layer\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#visualising-the-output-in-tmap",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#visualising-the-output-in-tmap",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Visualising the output in tmap",
    "text": "Visualising the output in tmap\nThe code chunk below will display a raster object into a cartographic quality map using the tmap package. Notice that the raster values are encoded explicitly onto the raster pixel using the values in the “v” field.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(palette = \"viridis\", title = \"layer\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Comparing spatial point patterns using KDE",
    "text": "Comparing spatial point patterns using KDE\nIn this section, we will compare the KDE of childcare facilities in Punggol, Tampines, Chua Chu Kang and Jurong West (planning areas)\n\nExtracting study area\nThe code chunk below extracts the target planning areas from mpsz_sf\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nThe code chunks below plot the different target planning areas using tmap_arrange().\n\npunggol &lt;- tm_shape(pg) + \n  tm_polygons() + tm_layout(title = \"Punggol\")\n\ncck &lt;- tm_shape(ck) + \n  tm_polygons() + tm_layout(title = \"Chua Chu Kang\")\n\ntampines &lt;- tm_shape(tm) + \n  tm_polygons() + tm_layout(title = \"Tampines\")\n\njwest &lt;- tm_shape(jw) + \n  tm_polygons() + tm_layout(title = \"Jurong West\")\n\ntmap_arrange(punggol, tampines, cck, jwest, asp=2, ncol=2, nrow = 2)\n\n\n\n\n\n\n\n\n\n\nCreating owin object\nThe code chunk below converts the four objeects into owin which is a requirement for analysing with spatstat\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\nCombining childcare points and the study area\nThe code chunk below extracts the childcare points/events that are within each of the target areas\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nWe use rescale.ppp() in the next code chunk to transform the unit of measure from meter to kilometer\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below s used to plot the four target areas and the locations of their childcare centres\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nComputing KDE\nThe code chunk below computes the KDE of the four target areas. bw.diggle() is the method used to compute for the bandwidths\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\nTo enable comparisons, we can set the bandwidth to 250m using the code chunk below\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on/Hands-On_Ex03/Hands-On_Ex03.html#nearest-neighbour-analysis",
    "title": "First Order Spatial Points Analysis Methods",
    "section": "Nearest Neighbour Analysis",
    "text": "Nearest Neighbour Analysis\nFor the succeeding section, we perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() from spatstat.\nThe test hypotheses for these are:\n\n\\(H_0\\) - The distribution of event locations (childcard service centres) is random\n\\(H_1\\) - The distribution of event locations is not random\n\nFor our testing, 95% confidence interval will be used\n\nTesting spatial point patterns using Clark-Evans test\nThe code chunk below runs the test on childcareSG_ppp\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe resulting p value ( \\(2.2 * 10^{-16}\\)) is very small and is below our significance level of 5%. Based on this, we reject the null hypothesis and conclude that the childcare centres are not randomly distributed.\n\n\nClarke-Evans test on individual planning areas\nThe code chunks below runs clarkevans.test() on the target areas separately.\nThe outputs show that the test rejects the null hypothesis for Tampines and Jurong West, but not for the other two. (i.e., it concludes that the childcare centres in Tampines and in Jurong West are not randomly distributed)\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.91415, p-value = 0.1996\nalternative hypothesis: two-sided\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.77989, p-value = 7.112e-05\nalternative hypothesis: two-sided\n\n\n\nclarkevans.test(childcare_pg_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.88576, p-value = 0.08783\nalternative hypothesis: two-sided\n\n\n\nclarkevans.test(childcare_jw_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_jw_ppp\nR = 0.88937, p-value = 0.04711\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this hands-on exercise, we learn some more SPPA with Network Constrained Spatial Point Patterns Analysis or NetSPPA. This is a collection of SPPA methods that is used to analyse spatial point events occuring on or alongside a network– which can be a road network, river network, etc.\nWe will be using the spNetwork package to derive the network kernel density estimation (NKDE) and then we perform analysis on the G-function and K-Function.\nThis exercise is based on Chapter 7 of Dr Kam’s online book which can be accessed here."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#data-sources",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#data-sources",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Data Sources",
    "text": "Data Sources\nData for this exercise are from public sources and will be used to analyse the distribution of childcare centers in the Punggol planning area. Two datasets in ESRI shapefile format will be used:\n\nA line feature geospatial dataset which includes the road network of Punggol planning area\nA point feature geospatial dataset which includes the location of childcare centers in the Punggol planning area"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#installing-and-launching-r-packages",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#installing-and-launching-r-packages",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nThis exercise will make use of five R packages: sf, spNetwork, tidyverse, and tmap.\n\nsf - for importing, managing and processing vector-based geospatial data\ntidyverse - collection of packages for performing data importation, wrangling and visualization\ntmap - for plotting cartographic quality maps\nsPNetwork - provides functions for performing SPPA methods like KDE and K-function on a network. The package can also be used to build spatial matrices to conduct traditional spatial analyses with spatial weights based on reticular distances\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#preparing-the-lixels-objects",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#preparing-the-lixels-objects",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Preparing the lixels objects",
    "text": "Preparing the lixels objects\nBefore computing the NKDE, SpatialLines objects need to be cut into lixels with a specified minimal distance. We do this using lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\nThe second argument of the function is lx_length which stands for the lixel length and was set to 700. The minimum lixel lngth is set to 375 by the mindist argument. If the length of the final lixel is shorter than mindist then it is added to the previous lixel. If mindist is NULL, then it is set to maxdist / 10."
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#generating-line-centre-points",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#generating-line-centre-points",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Generating line centre points",
    "text": "Generating line centre points\nNext, we use line_center() of spNetwork to generate a SpatialPointsDataFrame with line centre points as in the code chunk below. The centres will be located in the middle of the line based on the length.\n\nsamples &lt;- lines_center(lixels)"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#performing-nkde",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#performing-nkde",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Performing NKDE",
    "text": "Performing NKDE\nThe code chunk below computes the NKDE\n\ndensities &lt;- nkde(network, \n                  events = st_zm(childcare),\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nA few points on the arguments in the code chunk above:\n\nThe st_zm() function drops the z coordinate of childcare since the function requires two-dimensional inputs, while childcare has 3\nkernel_name is set to quartic but can be also set to other kernel methods like: triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov or uniform\nmethod is currently set to use simple method to be used to calculate the NKDE. There are three popular methods that are used\n\nsimple - distances between events and sampling points are replaced by network distances. The formula of the kernel is adapted to calculate the density over a linear instead of an areal unit\ndiscontinuous - equally divides the mass density of an event at the intersection of the lixels.\ncontinuous - divides the mass of the density at the intersection but adjusts the density before the intersection to make the function continuous"
  },
  {
    "objectID": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#visualizing-nkde",
    "href": "Hands-on/Hands-On_Ex05/Hands-On_Ex05.html#visualizing-nkde",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Visualizing NKDE",
    "text": "Visualizing NKDE\nWe first insert the computed density values into the samples and lixels objects as a field density\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nBefore plotting, we rescale the distances of the objects from the current SVY21 default of meter to kilometer, by using a multiple of 1000\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code chunk below produces an interactive map using tmap. The resulting map reveals road segments with high density of childcare centres based on the intensity of the color (i.e., darker shading is more dense)\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class/In-class_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "In-class/In-class_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "Geospatial Analytics w/ Derek",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class/In-class_Ex02/In-class_Ex02.html",
    "title": "Spatial Point Pattern Analysis",
    "section": "",
    "text": "The exercise uses the data sources to be used in the upcoming Take Home Exercise:\n\nThailand Road accident data from 2019-2022 from Kaggle\nThailand Roads OpenStreetMap from HDX\nThailand - Subnational Administrative Boudaries shapefile from HDX\n\n\n\n\nThis exercise will make use of four R packages: sf, spatstat, tidyverse, maptools and tmap.\nThe code chunk below imports the already retired. We can still download it from Posit Public Package Manager snapshots by using the code below.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.com/cran/2023-10-13\")\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, spatstat, maptools)"
  },
  {
    "objectID": "In-class/In-class_Ex02/In-class_Ex02.html#data-sources",
    "href": "In-class/In-class_Ex02/In-class_Ex02.html#data-sources",
    "title": "Spatial Point Pattern Analysis",
    "section": "",
    "text": "The exercise uses the data sources to be used in the upcoming Take Home Exercise:\n\nThailand Road accident data from 2019-2022 from Kaggle\nThailand Roads OpenStreetMap from HDX\nThailand - Subnational Administrative Boudaries shapefile from HDX"
  },
  {
    "objectID": "In-class/In-class_Ex02/In-class_Ex02.html#installing-and-launching-r-packages",
    "href": "In-class/In-class_Ex02/In-class_Ex02.html#installing-and-launching-r-packages",
    "title": "Spatial Point Pattern Analysis",
    "section": "",
    "text": "This exercise will make use of four R packages: sf, spatstat, tidyverse, maptools and tmap.\nThe code chunk below imports the already retired. We can still download it from Posit Public Package Manager snapshots by using the code below.\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.com/cran/2023-10-13\")\n\nThe code chunk below uses p_load() of pacman package to check if the packages are installed in the computer. It installs them first if they are not. It then loads them into R.\n\npacman::p_load(sf, tidyverse, tmap, spatstat, maptools)"
  },
  {
    "objectID": "In-class/In-class_Ex02/In-class_Ex02.html#importing-the-aspatial-data-and-converting-to-sf",
    "href": "In-class/In-class_Ex02/In-class_Ex02.html#importing-the-aspatial-data-and-converting-to-sf",
    "title": "Spatial Point Pattern Analysis",
    "section": "Importing the Aspatial Data and converting to sf",
    "text": "Importing the Aspatial Data and converting to sf\nThe Thailand road accident data is in csv format but contains a field for longitude and another for latitude.\n\nrdacc_sf &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")  %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe data appears to have been loaded properly. With the code chunk below, we confirm the data is loaded with a little loss of data given we have filtered out records with invalid coordinates.\n\nrdacc_sf\n\nSimple feature collection with 81376 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -16183190 ymin: -936.228 xmax: 1200243 ymax: 4918525\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 81,376 × 17\n   acc_code incident_datetime   report_datetime     province_th province_en     \n *    &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;       &lt;chr&gt;           \n 1   571905 2019-01-01 00:00:00 2019-01-02 06:11:00 ลพบุรี        Loburi          \n 2  3790870 2019-01-01 00:03:00 2020-02-20 13:48:00 อุบลราชธานี   Ubon Ratchathani\n 3   599075 2019-01-01 00:05:00 2019-01-01 10:35:00 ประจวบคีรีขันธ์ Prachuap Khiri …\n 4   571924 2019-01-01 00:20:00 2019-01-02 05:12:00 เชียงใหม่     Chiang Mai      \n 5   599523 2019-01-01 00:25:00 2019-01-04 09:42:00 นครสวรรค์    Nakhon Sawan    \n 6   571982 2019-01-01 00:30:00 2019-01-07 12:46:00 แม่ฮ่องสอน    Mae Hong Son    \n 7   612782 2019-01-01 00:30:00 2019-10-25 14:25:00 ชุมพร        Chumphon        \n 8   599235 2019-01-01 00:35:00 2019-01-02 16:23:00 สิงห์บุรี       Sing Buri       \n 9   600643 2019-01-01 00:40:00 2019-01-11 10:01:00 สงขลา       Songkhla        \n10   599105 2019-01-01 00:45:00 2019-01-01 10:11:00 ตราด        Trat            \n# ℹ 81,366 more rows\n# ℹ 12 more variables: agency &lt;chr&gt;, route &lt;chr&gt;, vehicle_type &lt;chr&gt;,\n#   presumed_cause &lt;chr&gt;, accident_type &lt;chr&gt;,\n#   number_of_vehicles_involved &lt;dbl&gt;, number_of_fatalities &lt;dbl&gt;,\n#   number_of_injuries &lt;dbl&gt;, weather_condition &lt;chr&gt;, road_description &lt;chr&gt;,\n#   slope_description &lt;chr&gt;, geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "",
    "text": "Welcome to my website for my work in the course ISSS 626 - Geospatial Analytics and Applications during the August term of 2024 under Dr Kam Tin Seong.\nThe course covers theory and methods of geospatial analysis and the tools in R to implement such analyses."
  },
  {
    "objectID": "index.html#hands-on-exercises",
    "href": "index.html#hands-on-exercises",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "Hands-On Exercises",
    "text": "Hands-On Exercises\nHands-on exercises are assigned before each lesson to give us hands-on experience in using R on the geospatial analysis methods and functions we learned. We are given step-by-step instructions and explanations (through Dr Kam’s online book) which complement our pre-class reading, and prepares us for the in-class exercises.\n\nGeospatial Data Wrangling with R (for Session 1, 26 Aug ’24)\nChoropleth Mapping with R (for Session 1, 26 Aug ’24)\n1st Order Spatial Point Patterns Analysis Methods (for Session 2, 2 Sept ’24)\n2nd Order Spatial Point Patterns Analysis Methods (for Session 2, 2 Sept ’24)\nNetwork Constrained Spatial Point Pattern Analysis (for Session 3, 9 Sept 2024)\nSpatial Weights and Applications (for Session 4, 16 Sept 2024)"
  },
  {
    "objectID": "index.html#in-class-exercises",
    "href": "index.html#in-class-exercises",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "In-Class Exercises",
    "text": "In-Class Exercises\nIn each session, we go through a hands-on exercise to revise the readings for the lesson. The objective of these is to further reinforce the concepts and tools learned in the readings and in the take-home exercise. These will also go further into the analysis and interpretation of results.\n\nIntroduction to Geospatial Analytics (26 Aug ’24)\nSpatial Point Pattern Analysis - Data Load for Take-home Exercise 1 (2 Sept ’24)\nAdvanced Spatial Point Patterns Analysis (9 Sept ’24)"
  },
  {
    "objectID": "index.html#take-home-exercises",
    "href": "index.html#take-home-exercises",
    "title": "Geospatial Analytics and Applications (in R)",
    "section": "Take-Home Exercises",
    "text": "Take-Home Exercises\nTake-home exercises are where we students are able to apply the methods and techniques learned in class in real-world cases– using real-world data and aim to generate real insights.\nFor each of these, we are given a specific problem, objectives and a base data set. Each student will work on the problem independently, guided only by the previous exercises and lessons.\n\nGeospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.4-thailand-roads-open-streetmap-shapefile",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.4-thailand-roads-open-streetmap-shapefile",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.4 Thailand Roads Open StreetMap, Shapefile",
    "text": "B.4 Thailand Roads Open StreetMap, Shapefile\nThe second geospatial object is the street map shapefile. We will use the object network to contain the final road network for the study.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                      layer=\"hotosm_tha_roads_lines_shp\")\n\nRunning the above code confirms that the dataset is in multilinestring sf format and that it contains 2.8M records across 15 variables. It also shows that there is no CRS applied to the dataset.\nBased on these, the following steps need to be done: apply the right CRS/EPSG code of 32647 or the same as bmr_full, and, filter the network to only include BMR.\nThe code below does the first step of applying a reference system and updating the EPSG code to 32647 using st_set_crs() and st_crs() from the sf package.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                      layer=\"hotosm_tha_roads_lines_shp\") %&gt;%\n  st_make_valid() %&gt;% st_set_crs(4326) %&gt;% st_transform(crs = st_crs(bmr_full))\n\nThe code below then finds the network within BMR by using st_intersection() to find the overlap between the full road network and the BMR boundary.\n\nbmr_network &lt;- st_intersection(network, bmr_full)\n\nCalling the object name allows us to inspect the contents.\n\nbmr_network\n\nThe size of the object has now been reduced to 585K features from the original 2.8M. This still appears a very large number if we want to visualize the data, so we need to inspect if there are any opportunities to reduce the dataset by excluding any irrelevant records.\nThe data includes a column named highway which gives information on the the type or classification of the road.\n\nggplot(bmr_network, aes(x = reorder(highway, table(highway)[highway]))) +\n  geom_bar() +\n  coord_flip() +\n  ggtitle(\"Number of Roads by Highway type\") +\n  theme_minimal() +\n  geom_text(stat='count', aes(label=..count..), hjust=-0.3) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12),\n    axis.text.x = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(x = \"Number of Records\", y = \"Highway Type\")\n\nThe resulting chart shows that roads with highway type of residential and service make up 522K of the 585K roads in the dataset. We refer to the OpenStreetMap wiki page to see the definition of the different types of highways in the Thailand map and see that these two highway types are access roads for residences or specific buildings. For our objective, we should be able to limit to roads where accidents (are expected to frequently) happen, and only to roads that should be accessible by vehicles. Going through the definition of the highway types, we see that the following 6 types could be out of scope for our study:\n\nresidential - road within a residential area that gives public access to one or multiple residences\nservice - minor road that gives access to buildings or places outside a residential area (e.g., to a religious site, an attraction, part of an estate)\nfootway - pathways designed for pedestrian access\ntrack - road whose only function is to provide access to surrounding land, and is most of the time unpaved\npath - multi-purpose path intended for non-motor vehicles\nsteps\n\nWe can then use the following code chunk which uses the filter() function to remove these classifications from the current network object. We call the object name in the succeeding code chunk to check the new dataset.\n\nbmr_network &lt;- bmr_network %&gt;% \n  filter(!(highway %in% c(\"residential\", \"service\", \"footway\", \"track\", \"path\", \"steps\")))\n\n\nbmr_network\n\nSimple feature collection with 34056 features and 14 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 590124.8 ymin: 1484506 xmax: 712235 ymax: 1579041\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n           name                    name_en        highway  surface smoothness\n1    ถนนฉลองกรุง         Chalong Krung Road      secondary    paved       &lt;NA&gt;\n2          &lt;NA&gt;                       &lt;NA&gt; secondary_link     &lt;NA&gt;       &lt;NA&gt;\n3    ถนนฉลองกรุง         Chalong Krung Road      secondary concrete       &lt;NA&gt;\n4   ถนนเอราวัณ 1              Erawan 1 Road       tertiary     &lt;NA&gt;       &lt;NA&gt;\n5     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n6     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n7     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n8     ถนนลำลูกกา            Lam Luk Ka Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n9  ถนนบรมราชชนนี Borommaratchachonnani Road          trunk  asphalt       &lt;NA&gt;\n10         &lt;NA&gt;                       &lt;NA&gt;   unclassified     &lt;NA&gt;       &lt;NA&gt;\n   width lanes oneway bridge layer source      name_th     osm_id  osm_type\n1   &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   ถนนฉลองกรุง 1125681229 ways_line\n2   &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  472283206 ways_line\n3   &lt;NA&gt;     2    yes    yes     1   Bing   ถนนฉลองกรุง  116847248 ways_line\n4   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  ถนนเอราวัณ 1  378672881 ways_line\n5   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา 1312138113 ways_line\n6   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา 1312138112 ways_line\n7   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา  155900618 ways_line\n8   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;    ถนนลำลูกกา  156365723 ways_line\n9   &lt;NA&gt;     3    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; ถนนบรมราชชนนี  615741634 ways_line\n10  &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;  106732198 ways_line\n                         geometry\n1  LINESTRING (693686.1 151979...\n2  LINESTRING (692949.1 151886...\n3  LINESTRING (692810.8 151863...\n4  LINESTRING (677182.3 156542...\n5  LINESTRING (676813.7 154284...\n6  LINESTRING (677134.2 154283...\n7  LINESTRING (675989.4 154300...\n8  LINESTRING (676815 1542831,...\n9  LINESTRING (632625.1 152356...\n10 LINESTRING (620655.3 152906...\n\n\nThe new road network object is now reduced to 34K records or roads which is a 94% reduction in the number of records. We will use some visual inspection to see if this reduction in records will affect our analysis. The two code chunks below plot the road network within the boundaries, while the second plots the three objects together. We use the tmap function to create these maps.\n\nBMR filtered road network onlyBMR filtered road network with road accident dataset\n\n\n\ntm_shape(bmr_full) +\n  tm_polygons(col = \"lightgrey\") +\n  tm_shape(bmr_network) +\n  tm_lines(col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(bmr_full) +\n  tm_polygons(col = \"lightgrey\") +\n  tm_shape(bmr_network) +\n  tm_lines(col = \"black\") +\n  tm_shape(bmracc) +\n  tm_dots(col = \"red\", alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\n\nFrom these two maps, we see that:\n\nwhile we have filtered 90% of the original records, the resulting map still appears dense, especially in some central areas; and,\nthe road accident locations appear to fall along the network\n\nBased on these, we will go ahead with this version of the network for our analysis.\nThe following code writes the resulting network into an rds file for more convenient loading in the future.\n\nwrite_rds(bmr_network, \"data/rds/bmr_network.rds\")"
  },
  {
    "objectID": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.5-resolving-duplicate-points",
    "href": "Take-home/Take-home_Ex01/Take-home_Ex01.html#b.5-resolving-duplicate-points",
    "title": "Geospatial Analysis for Public Good: A Data-driven Perspective on Road Traffic Accidents in the Bangkok Metropolitan Region",
    "section": "B.5 Resolving duplicate points",
    "text": "B.5 Resolving duplicate points\nIn this section, we perform some additional transformations to perform the required analyses.\nFirst, we check the event or accident dataset to see if there are any duplicated data points or locations as the methods require that the points are unique. The code below checks if any duplicate points exist. Note that we specify the column in the argument as we are double-checking duplicate locations rather than completely duplicate records.\n\nany(duplicated(bmracc$geometry))\n\n[1] TRUE\n\n\nAs the code returned TRUE, it confirms the presence of duplicate points, we use st_jitter() from the sf package to introduce some jitter to each point and ensure that points do not lie on the same location. Without any additional arguments, the function uses a default factor 0.002 of the bounding box diagonal as the bounds for the amount of jitter introduced. In the code below, we define an amount of 0.01 instead.\n\nbmracc &lt;- st_jitter(bmracc, 0.01)\n\nRerunning the check using duplicated() shows that there are no duplicate points anymore.\n\nany(duplicated(bmracc$geometry))\n\n[1] FALSE"
  }
]